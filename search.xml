<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title></title>
    <url>%2F2019%2F07%2F14%2Fpaper%2F%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%2FSSVAE%2F</url>
    <content type="text"><![CDATA[]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2019%2F07%2F14%2F%E6%96%87%E6%9C%AC%E7%9B%B8%E4%BC%BC%E5%BA%A6%2F</url>
    <content type="text"><![CDATA[文本相似度的算法 向量化 词频统计 tf-idf 距离计算方法 余弦相似度 \[ \frac{a . b}{|a|.|b|} \] 编辑距离 d[i,j]=min(d[i-1,j]+1 、d[i,j-1]+1、d[i-1,j-1]+temp) str1[i] == str2[j]，用temp记录它，为0。否则temp记为1 SimHash + 汉明距离 Jaccard相似性系数 曼哈顿距离 欧几里得距离]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2019%2F06%2F08%2F%E7%99%BE%E9%9D%A2%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[第四章: 降维 4.1 PCA 最大方差理论 如何定义主成分？ 利用空间变换， 利用较低维度数据最大程度的表征原始数据，从而达到降维的目的。 如何设计目标函数进行主成分的提取？ 给定一堆数据点 \((x_1, x_2, ..., x_n)\) 我们将其通过线性变换可得 $w^Tx_ i $ （此处向量均为列向量） 这个变换可以理解为是 \(x_i\) 投影在 \(w\) 向量方向得到的向量。 因此投影得到的向量的长度(方差)是 \(w^Tx_ix_i^Tw\) , 对所有的 \(x_i\) 进行变换后求和可得： \[\sum_i w^Tx_ix_i^Tw= w^T (\sum_i x_i x_i^T) w\] 在 \(w​\) 只表征方向的情况下，我们希望这个值越大越好。因此可以得到以下优化问题： \[\left\{ \begin{align} \max &amp; w^T (\sum_i x_i x_i^T) w \\ s.t. &amp; w^Tw=1 \end{align}\right.\] 针对这个目标函数如何对PCA 问题进行求解 对样本数据进行中心化处理 求样本的协方差矩阵 协方差矩阵进行特征值分解， 将特征值从大小到小排列 取特征值前 \(d\) 大对应的特征向量 \(w_1, w_2,..., w_d\). 将 \(n\) 维的样本映射到\(d\) 维。 降维后的信息占比为 \[\eta = \sqrt{\frac{\sum_{i=1}^d \lambda_i^2}{\sum_{i=1}^n \lambda_i^2} }\] 4.2 PCA 最小平方误差理论 从回归的角度来定义 PCA 并求解 定义每个点 \(x_k\) 到超平面 \(D\) 的距离为： \[\mbox{distance}(x_k, D) = \parallel x_k-\tilde{x_k} \parallel_2\] 其中 \(\tilde{x_k}\) 表示 \(x_k\) 在超平面上的投影向量，并且假设 \(D\) 是由 \(d\) 个标准正交基 \(W=\{w_1, w_2, ...,w_d\}\) 构成。 投影向量 \(\tilde{x_k}\) 用这组标准正交基线性表示： \[\tilde{x_k}=\sum\limits_{i=1}^d (w_i^Tx_k)w_i\] PCA 的优化目标函数 \[\left\{ \begin{align} \arg\min\limits_{w_1, w_2, ... w_d} &amp; \sum\limits_{k=1}^n \parallel x_k - \tilde{x_k} \parallel_2^2 \\ s.t &amp; w_i^T w_j = \delta_{ij} =\left\{ 1, i=j ;0, i\neq j \right. \end{align}\right.\] 将 \[\tilde{x_k}=\sum\limits_{i=1}^d (w_i^Tx_k)w_i\] 带入上述公式得到： \[ \left\{ \begin{align} \arg\max_W &amp; tr(W^T XX^T W),\\ s.t. &amp; W^TW= I. \end{align} \right. \] 该公式和4.1中的目标相似。计算方法一样。 4.3 线性判别分析 PCA 是一种无监督的降维方法，LDA 是一种有监督的降维的方法，其将标签信息考虑进去了。 - 如何设计目标函数使得降维的过程中不损失类别信息？ - 可以采用考虑线性判别分析的方法： 最大化类间距离和最小化类内距离 - 目标函数是： \[J(w) = \frac{w^T(u_1-u_2)(u_1-u_2)^Tw}{\sum_{x \in c_i} w^T (x-u_i)(x-u_i)^Tw}\] - 在这种目标下，如何进行求解？ - 定义类间散度矩阵 \(S_B = (u_1-u_2)(u_1-u_2)^T\) , 类内散度矩阵是 \(S_w=\sum_{x \in c_i }(x-u_i) (x-u_i)^T\) 。 则目标函数可以写成： \[J(w) = \frac{w^T S_B w}{w^T S_w w}\] - 对 \(w\) 进行求偏导然后令 \(\lambda = J(w)\) 可以得到： \[ S_w^{-1} S_Bw = \lambda w \] 所以目标就成了求解 \(S_w^{-1}S_B\) 最大的特征值问题， 而投影方向就是这个特征值对应的特征向量。 - 多类别的线性判别分析怎么做？ 类间距离\(S_b = \sum\limits_{j=1}^N m_j (u_j-u)(u_j-u)^T\), 表示每个类的中心和所有样本的中心的距离。 \(S_w\) 不变。\(m_j\) 表示第 \(j\) 个类别中的样本个数。 因此将最大化的目标是： \[J(W) = \frac{tr(W^TS_bW)}{tr(W^TS_wW)} \] 最后的求解目标变成了广义特征值的求解 \[S_b w = \lambda S_w w\] 4.4 线性判别分析和主成分分析 如何从应用的角度分析 LDA 和 PCA 的异同 目标： PCA 选择投影后数据方法最大的方向（无监督）， LDA 利用了标签的信息选择 类内方差最小而类间方差最大。 应用 PCA: 语音去噪 LDA: 从语音中选择是哪个人的声音 第五章：非监督学习 5.1 K 均值聚类 简述 K 均值聚类的具体步骤（hk: 一种EM算法）？ 数据预处理，数据归一化， 离群点的处理 随机选取 \(K\) 个族中心： \(u_1^{(0)}, u_2^{(0)}, ..., u_K^{(0)}\) 定义代价函数为： \(J(c,u) = \min\limits_u \lim\limits_c \sum\limits_{i=1}^M \parallel x_i - x_{c_l} \parallel^2\) 重复下面的过程直到 \(J\) 收敛。 对于每个样本 \(x_i\) 将其分配到距离最近的族。 \[ c_i^{(t)} \leftarrow \arg \min_k \parallel x_i - u_k^{(t)} \parallel^2; \] 对于每个类族 \(k\), 重新计算该类的族的中心 \[ u_k^{(t+1)} \leftarrow \arg\min_u \sum \parallel x_i -u \parallel^2 \] \(K\) 均值算法的优缺点是什么？ 缺点 结果受初值和和离群点的影响不稳定。 结果通常不是全局最优而是局部最优 无法很好的分类拒族分布差别比较大的情况（例如：一个类的样本是 另一个的100倍） 优点 时间复杂度为 \(O(NKt)\) \(N\) 是数据对象的数目， \(K\) 是族数， \(t\) 是迭代次数。接近于线性。 \(K\) 均值算法的调优算法？ 数据归一化和离群点处理 均值和方差大的维度将对数据的聚类结果产生决定性的结果 合理选择\(K\)值 手肘法 （横轴为\(K\)值，纵坐标为损失） Gap Statistic 方法。（蒙特卡洛模拟） 采用核函数 针对 \(K\) 均值算法的缺点，有哪些改进的模型？ \(K\) 均值算法的主要缺点如下： 需要人工预先确定初始 \(K\) 值， 且该值和真实的数据分布未必吻合。 \(K\) 均值只能收敛到局部最优， 效果受到初始值影响很大。 易受噪点的影响。 样本只能被划分到单一的类中。 改进初始值对结果的影响 K-means++ 算法 选取的第 \(K\) 个值要尽量的远离前 \(K-1\) 个已经选择好了的点。 改进的 \(K\) 值选择方法 ISODATA 算法 （迭代自组织数据分析方法） 当属于某个类别的数据点过少的时候就把该类别去除（分离操作）， 当属于某个类别的样本数过多、分散程度较大的时候，把该类别分成两个子类别（合并操作）。 该方法所需的超参数：1. 预期的聚类中心数目 \(K_0\); 2. 每类所要求的最少样本数目 \(N_{\text{min}}\); 3. 最大方差 Sigma; 4. 两个聚类中心所允许的最小距离 \(D_{\text{min}}\)。 5.2 高斯混合模型 理论上高斯混合分布可以拟合出任意类型的分布。 - 高斯混合模型的核心思想是什么？ 假设数据可以看做是从多个高斯混合分布中生成出来的。高斯混合模型（hk:应该是做了独立同分布的假设的。）的公式为： \[ p(x) = \sum\limits_{i=1}^K \pi_i N(x|u_i, \sigma_i) \] 高斯混合模型是如何迭代计算的？ EM 算法的迭代过程 E步骤： 根据当前的参数，计算每个点由某个分模型生成的概率。 M步骤： 使用E步估计出的概率，来改进每个分模型的均值，方差和权重。 高斯混合模型与 \(K\) 均值算法的异同? 共同点： 1. 都可用于聚类算法； 2.都采用EM算法来求解；3. 都往往只能够收敛到局部最优； 不同点： 1. 高斯混合分布能够给出一个样本属于某个类的概率； 2. 高斯混合分布还可以用于概率密度的估计；3. 高斯混合分布能够用于生成新的样本点。 5.3 自组织映射神经网络（self-origanizing map, SOM） 自组织映射神经网络是如何工作的？ SOM 本质上是一个两层的神经网络，包括输入层和输出层（竞争层）；这是一种无监督的学习算法。 初始化： 所有的连接权重都用小的随机值进行初始化； 竞争： 计算具有最小判别函数值的特定神经元为胜利者； 每个神经元 \(j\) 的判别函数为 \(d_j(x) = \sum\limits_{i=1}^D (x_i-w_{i,j})^2\)。 合作： 获胜的神经元 I(x) 决定了兴奋神经元拓扑邻域的空间位置，计算邻近神经元的更新程度 : \(T_{j, I(x)}(t) = \exp\left( -\frac{S^2_{j, I(x)}}{2\sigma(t)^2} \right)\), \(S_{i,j}\)表示竞争层神经元\(i\) 和 \(j\) 之间的距离。 \(\sigma(t) = \sigma_0 \exp(-\frac{t}{\tau_\alpha})\) 适应： 调整兴奋神经元的连接权重： \(\Delta w_{ji} = \eta (t) \cdot T_{j,I(x)}(t)\cdot(x_i - w_{ji})\), 调整学习率： \(\eta(t) = \eta_0 \exp\left( -\frac{t}{\tau_\eta} \right)\) 迭代： 知道特征映射趋于稳定 自组织映射神经网络与K均值算法有何区别？ K 均值算法需要事先定下类的个数，而 SOM 中聚类的结果可能小于神经元的个数。 K 均值算法为每个输入数据找到相似的类之后，只更新这个类的参数，而SOM会更新附近点的参数。 SOM 的可视化比较好，而且具有优雅的拓扑关系图。 怎样设计自组织映射神经网络并设定网络训练参数？ 设定输出层神经元的数量 该值和样本类别相关， 在不清楚的情况下可以设定较多的节点数。以便较好的映射样本的拓扑结构。 设计输出层节点的排序 这东西需要考虑实际问题的物理意义； 例如一般的分类问题一个输出节点可以代表一个模式类，颜色空间和旅行路径问题，二维平面空间比较直观。 权值的初始化 尽量使权值的初始化位置与输入样本的大概分布区域充分重合。比较简单的方法有从训练数据中随机选取 \(m\) 个样本作为初始权重； 也可以随机初始化。 设计拓扑领域 领域不断缩小， 各种拓扑形状都可以（正方形，圆形，六边形...） 设计学习率 学习率是一个递减的函数 5.4 聚类算法的评估 假设没有外部标签数据，如何评估两个聚类算法的优劣 常见的数据簇： 1. 中心； 2. 密度； 3. 连通； 4. 概念。 聚类评估过程 估计聚类的趋势： 1. 聚类误差是否随类别增加而线性增加； 2. 霍普金斯统计量。 判断数据簇数： 1. 手肘法； 2. Gap Statistic 方法 测量聚类质量： 1. 轮廓系数； 2. 均方标准偏差； 3. R方； 4.改进的hubert统 ## 第六章: 概率图模型 ### 6.1 概率图模型的联合概率分布 如何写出 6.1(a) 中贝叶斯网络的联合概率分布？（菱形带方向） 如何写出 6.1(b) 中马尔可夫网络的联合概率分布？（菱形不带方向） 最大团： 由一个节点构成的子集中，任意两点之间都存在边相连，则这个子集中的所有节点构成了一个团。 6.2 概率图表示 解释朴素贝叶斯模型的原理。 预测指定样本属于特定类别的概率 \(P(y_i |x)\) 来预测该样本的所属类别， 即： \[y=\max\limits_{y_i} P(y_i |x )\] \(P(y_i|x)\) 可以写成： \(P(y_i|x) = \frac{P(x|y_i)P(y_i)}{P(x)}\) 给出朴素贝叶斯模型的概率图模型？ 解释最大熵模型的原理，并给出概率图模型的表示？ 分布 \(P(x)\) 的熵定义是： \(H(P) = -\sum\limits_x P(x)\log P(x)\) 条件熵： \(H(P)=-\sum\limits_{x,y} \tilde{P}(x) P(y|x) \log P(y|x)\) 最大熵模型的学习等价于约束最优化问题： \[ \begin{align} \max_P H(P) &amp;= -\sum\limits_{x,y} \hat{P}(x)P(y|x)\log P(y|x), \\ s.t., E_{\hat{p}}(f_i) &amp;= E_p (f_i), \forall i=1,2,...,M,\\ \sum\limits_y P(y|x) &amp;= 1. \end{align} \] 求解之后得到的最大熵模型的表示形式为 \[ P_w(y|x) = \frac{1}{Z} \exp(\sum\limits_{i=1}^M w_i f_i(x,y)) \] 最大熵模型的概率图： （无向图模型） 6.3 生成式模型与判别式模型 常见的概率图模型中，哪些是生成式模型， 哪些是判别式模型？ 判别式模型： 判别式模型是直接对条件概率分布 \(P(Y,Z|X)\) 进行建模， 然后消掉无关变量 \(Z\) 就可以得到对变量集合 \(Y\) 的预测，即 \(P(Y|X) = \sum\limits_z P(Y,Z|X)\) 生成式模型： 生成式模型对联合概率分布 \(P(X,Y,Z)\) 进行建模 \(P(Y|X) = \frac{P(X,Y)}{P(X)} = \frac{\sum_z P(X,Y,Z)}{\sum_{Y,Z}P(X,Y,Z)}\) 常见的生成式模型： 朴素贝叶斯、贝叶斯网络、pLSA、LDA、隐马尔可夫模型。 常见的判别式模型： 最大熵模型、条件随机场。 ### 6.4 马尔可夫模型 如何对中文分词问题用隐马尔科夫模型进行建模和训练？ 马尔科夫模型的三个问题： 1. 概率计算问题 （前向后向算法）； 2. 预测问题（维特比算法）； 3.学习问题（Baum-Welch算法） 问题： 将中文分词问题视为是一个序列标注问题。(隐状态是每个字的标注) 最大熵马尔可夫模型为什么会产生标注偏置问题？ 如何解决？ 最大熵马尔可夫模型 隐马尔可夫模型是对隐状态序列和观测状态序列的联合概率 \(P(x,y)\) 进行建模的生成式模型，而最大熵马尔可夫模型是直接对标注的后验概率 \(P(y|x)\) 进行建模的判别式模型。 最大熵模型存在的标注偏置问题（P131） 问题： 由于局部归一化的影响，隐状态会倾向于转移到那些后续状态可能更少的状态上，以提高整体的后验概率， 这就是标注偏置问题。 解决方法 条件随机场的归一化因子是在全局范围内进行归一化，枚举了整个隐状态序列 \(x_{1...n}\) 的全部可能，从而解决了局部归一化带来的标注偏置问题。 6.5 主题模型 将具有相同主题的词或词组映射到同一纬度上去。 常见的主题模型有哪些？ 试介绍其原理。 pLSA (Probabilistic Latent Semantic Analysis) 生成模型 符号说明： \(d\): 文章； \(z\): 主题； \(w\):词 给定文章生成词的概率是： \(p(w|d)=\sum\limits_z p(w|z, d)p(z|d)\) 假设在给定主题 \(z\) 的情况下，生成词 \(w\) 的概率与特定的文章无关则可得：\(p(w|d) = \sum\limits_z p(w|z)p(z|d)\) 整个语料库中文本生成概率用似然函数表示为: \[L = \prod\limits_m^M \prod\limits_n^N p(d_m,w_n)^{c(d_m, w_n)}\] Log 似然函数可以写为： \[\begin{align} l&amp;=\sum\limits_{m}^M\sum\limits_n^Nc(d_m, w_m)\log p(d_m,w_n)\\ &amp;=\sum\limits_m^m \sum\limits_n^N c(d_m,w_n)\log \sum\limits_k^K p(d_m) p(z_k|d_m)p(w_n|z_k) \ \end{align}\] 其中 \(p(w_n|z_k)\) 和\(p(z_k|d_m)\)是待估的参数。 求解方法 : 最大期望算法。 LDA LDA 采用的是贝叶斯学派的思想认为带估计的参数（主题分布和词分布）不再试一个固定的常数，而是服从一定分布的随机变量。 语料库的生成过程： 对文本库中的每一篇文档 \(d_i\) ，采用以下操作： 从超参数为 \(\alpha\) 的狄利克雷分布中抽样生成文档 \(d_i\) 的主题分布\(\theta_i\) 对文档 \(d_i\) 中的每一个词进行以下3个操作： 从多项式分布 \(\theta_i\) 中抽样生成它所对应的主题 \(z_{ij}\) 从超参数为 \(\beta\) 为狄利克雷分布中抽样生成主题 \(z_{ij}\) 对应的词分布 \(\psi_{z_{ij}}\) 从代表词的多项式分布 \(\psi _{z_{ij}}\) 中抽样生成词 \(w_{ij}\) 求解方法： 吉布斯采样（Gibbs Sampling） 如何确定 LDA 模型中的主题 训练数据的分类： 训练集 \(60\%\), 验证集\(20\%\), 测试集\(20 \%\) 。 评价指标： (困惑度 perplexity) \[\text{perplexity}(D) = \exp \left\{ -\frac{\sum\limits_{d=1}^M \log p(w_d)}{\sum\limits_{d=1}^N N_d} \right\}\] 其中 \(M\) 是文档的总数， \(w_d\) 为文档 \(d\) 中单词所组成的词袋向量， $p(w_d) $ 为模型所预测的文档 \(d\) 的生成概率， \(N_d\) 为文档 \(d​\) 中单词的总数。 第一种方法： 选择当主题数增加困惑度指标在训练集上继续下降但在验证集上反而增长的主题个数作为超参数。 第二种方法： 在 LDA 的基础上融入分层狄利克雷过程，构成一种非参数主题模型 HDP-LDA。 这种方法不需要预先指定主题的个数，模型可以随着文档的数目变化而对主题个数进行调整，缺点是会使概率图模型变得更加复杂。 如何用主题模型解决推荐系统中的冷启动问题？ 目标： 优化点击率、转化率或用户体验（用户留存时间、留存率等） 类别： 用户冷启动、物品冷启动、系统冷启动。 第八章： 采样 8.1 采样的作用 举例说明采样在机器学习中的应用 给定概率分布，模拟产生随机事件 用少量的样本点（经验分布）来近似总体分布 重采样。（处理数据不平衡问题） 对复杂模型进行随机模拟，进行近似求解或推理 什么是自助法和刀切法 自助法： 从给定训练数据集中有放回的均匀采样。 刀切法：每次从样本集中删除一个或者几个样本，剩余的样本成为“刀切”样本。 8.2 均匀分布随机数 如何编程实现均匀分布随机数生成器？ 线性同余法： \(x_{t+1}=(a \cdot x_t + c) \mod m\) 伪随机数，该算法最多只能产生 \(m​\) 个不同的随机数。 多次产生随机数之后该方法得到的随机数序列会进入循环周期。 gcc 中的 glibc 设置的 超参数值为： \[m=2^31-1,\\a=1103515245, \\c=12345​\] 真正的随机数只存在于自然界的物理现象中。 线性同余法中的随机种子一般如何选定？ 当前的系统时间 8.3 常见的采样方法 抛开那些针对特定分布而精心设计的采样方法，说一些你所知道的通用采样方法或采样策略，简单描述它们的主要思想以及具体操作步骤。 直接用均匀采样的一些扩展方法来产生样本点： 有限离散分布可以用轮盘赌算法来采样。 函数变换采样法： \(u=\varphi(x)\) , 则他们的概率密度函数有如下关系 \(p(u)|\varphi&#39;(x)|=p(x)\) \(u\) 采样简单， 能够得到复杂的分布。 逆采样法： 假设待采样的目标分布的概率密度函数为 \(p(x)\), 他的累积概率分布函数是： \[u=\Phi(x) = \int_{-\infty}^x p(t)d_t \] 从均匀分布 \(U(0, 1)\) 产生一个随机数 \(u_i\); 计算 $x_i = ^{-1} (u_i) $, 其中 \(\Phi^{-1}(\cdot)\) 是累积分布函数的逆函数。 拒绝采样（Rejection Sampling） 对于目标分布 \(p(x)\) , 选取一个容易采样的参考分布 \(q(x)\) ,使得对于任意\(x\) 都有 \(p(x) \leq Mq(x)\) 则可以按如下过程进行采样： 从参考分布 \(q(x)\) 中随机抽取一个样本 \(x_i\) ; 从均匀分布 \(U(0, 1)\) 产生一个随机数 \(u_i\); 如果 \(u_i &lt; \frac{p(x_i)}{ Mq(x_i)}\) ，则接受样本 \(x_i\); 否则拒绝。 自适应拒绝采样 同拒绝采样的方法，只不过采用分段线性函数来覆盖目标分布的对数 \(\ln p(x)\)。 重要性采样(Importance Sampling) 找一个比较容易抽象的参考分布 \(q(x)\) , 并令 \(w(x) = \frac{p(x)}{q(x)}\) , 从参考分布 \(q(x)\) 中抽取 \(N\) 个样本 \(\{x_i\}\) , 然后按照其重要性进行重新采样。]]></content>
  </entry>
  <entry>
    <title><![CDATA[TextCNN]]></title>
    <url>%2F2019%2F03%2F14%2Fpaper%2F%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%2FTextCNN%2F</url>
    <content type="text"><![CDATA[Convolutional Neural Networks for Sentence Classification 输入(Embedding Layer) rand 随机初始化词向量。 static 采用 word2vec 词向量进行初始化，并且在模型训练的时候词向量不能够进行微调。 non-static 即拿word2vec训练好的词向量初始化, 训练过程中再对它们微调。 multichannel 每个单词生成多个词向量， 这里的词向量的数量体现通道的数量上。 输出（Output Layer） FC layer + Softmax Cross Entropy Loss 主体结构 卷积层 采用了高度为 【3，4， 5】宽度等于词向量维度的卷积核。 对每个高度的卷积核其卷积核数量是100。 没有padding 计算（batch 假设为1 ）： 假设输入的文本长度为 80， 词向量的维度是 300。 经过这一步我们可以得到 【1， 78，1，100 】，【1， 77，1, 100 】, [1, 76, 1, 100] 这三个tensor。 这里的四个维度分别表示 【batch size, height, width, channels】。 池化层 这里的 max pooling 从相同大小的 滤波器得到的 tensor 中选取出最重要的特征（不同位置最重要的特征）。 采用的是 max pooling 大小是 [1,78, 1, 1], [1, 77,1,1], [1,76,1,1] 计算 经过这样的操做，可以得到的tensor 分别是 [1, 1, 1, 100], [1, 1, 1, 100], [1, 1, 1, 100]。要把这三个给 输出层需要进行 concatenation 然后reshape就好了。]]></content>
      <categories>
        <category>Deep Learning</category>
      </categories>
      <tags>
        <tag>TextCNN</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[BERT]]></title>
    <url>%2F2019%2F03%2F14%2Fpaper%2FBERT%2F</url>
    <content type="text"><![CDATA[（一）目的 ​ 用无监督的方法（无标记的训练数据）来训练动态的词向量（词向量可以不固定，在不同的上下文中相同单词对应的词向量可以不同，因此该词向量来源于一个模型，模型的输出就是我们需要用于后续任务的词向量）。 ​ 我们需要训练一个模型，这个模型能够使得输出的每个位置的词向量具有联系上下文的能力，并且具有丰富的含义。 (二) 模型的输入输出和损失函数 输入两个句子。将每个句子对应的 token embedding , segment embedding 和 position embedding 进行相加。 输入： token embedding + segment embedding + position embedding token embedding 对每个单词进行随机初始化向量输入， 输入序列的开头加上【CLS】。如果输入是两个句子，可以在句子之间添加 【SEP】标记。正常情况下是输入一个序列，不需要加 【SEP】， 但是在训练的时候，针对QA等问题需要理解两个句子之间的关系的问题。因此在预训练中增加了一个对下一个句子的预测的任务（第三部分有讲到）。 segment embedding 第 i 个句子的 one-hot 向量表示。如果只有一个句子那就全是0了，如果有两个句子就是一个0，一个1, embedding 的维度要和 token embedding 的维度一样。 position embedding 随机初始化的位置向量，让模型自己去学，对于每个位置其位置向量是怎么样的。 输出 输出长度和输入长度相同，词向量的维度可以自己定义。 【CLS】 输出位置对应的向量用于表示包含有整个序列的语义表达。 所以在做分类或者第二个训练任务的时候用到的是这部分的输出。 损失函数 交叉熵损失函数。 将相应位置的输出，先需要进过一个全连接层将其维度和对应词向量的 one-hot 表示维度一致，然后计算交叉熵。 （三）预训练的任务 Masked LM 为了使得模型训练得到的输出具有理解上下文的含义，作者提出了采用 masked LM（MLM） 。 这里的 MLM 就是将随机的将句子中的一些词隐藏掉，然后根据文本的上下文对这写隐藏掉的词进行预测（可以理解为做完形填空）。 但是如果每次在训练的时候每次都对某个单词做了 mask 那么在测试的时候可能会出现这个单词不存在的现象。因此这里的mask 采用了下面的方法： 80%的时间真的用[MASK]取代被选中的词 my dog is hairy -&gt; my dog is [MASK] 10%的时间用一个随机词取代 my dog is hairy -&gt; my dog is apple， 防止模型将 【mask】就记作hairy了，迫使模型去考虑上下文。 10%的时间保持不变 my dog is hairy -&gt; my dog is hairy, 防止 fine-tuning 的时候模型会有一些没见过的词。 下一句预测 很多NLP的任务比如QA和NLI都需要理解两个句子之间的关系，而语言模型并不能直接反应这种关系。为了是预训练出来的模型很好的适应这些任务。 就是将 【cls】 位置对应的输出用来做分类。 如果输入的两个句子是连续的上下文词那么分类标签为1，如果不是就是0。 (四) 网络结构 ​ 基本版： 12-layer, 768-hidden, 12-heads, 110M parameters。 ​ 扩大版：24-layer, 1024-hidden, 16-heads, 340M parameters。 ​ （五）已训练好的模型和代码 uncased(不区分大小写) cased(区分大小写) multilanguage (多语言) chinese(中文) ​]]></content>
      <categories>
        <category>Deep Learning</category>
      </categories>
      <tags>
        <tag>BERT</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深度学习中的注意力机制]]></title>
    <url>%2F2019%2F03%2F14%2FAttentionMechanism%2FAttentionMechanismInDeepLearning%2F</url>
    <content type="text"><![CDATA[1. 深度学习中的注意力机制 来源 1.1 Encoder-Decoder 框架 图1. 抽象的文本处理领域的 Encoder-Decoder 框架 图2. RNN作为具体模型的Encoder-Decoder框架 \[ \begin{align} \text{Source} &amp;= &lt;x_1, x_2, ..., x_m&gt; \\ \text{Target} &amp;= &lt;y_1, y_2, ..., y_n&gt; \\ C &amp;= F(x_1, x_2, ..., x_m) \\ y_i &amp;= \mathcal{G} (\mathbf{C}, y_1, y_2, ..., y_{i-1}) \end{align} \] 1.2 Attention 模型 \[ \begin{align} y_i &amp;= \mathcal{G} (\mathbf{C_i} , y_1, y_2, ..., y_{i-1}) \\ C_i &amp;= \sum_{j=1}^{L_x} a_{ij} h_j \end{align} \] 注： Encoder-Decoder 框架中用于生成的隐藏内容\(C\)和Attention 中的隐藏内容\(C_i\)是不同的。 1.3 Attention 机制的本质思想 Attention 机制的本质思想 第一种解释 可以将 Source 中的构成元素想象成一系列的 &lt;Key, Value&gt; 数据对构成。 而 Query 可以理解成来自 Target 中的某个元素， 通过计算 Query 和 Key 的相似度或者相关度，得到每个 Key 对应 Value的权重系数， 然后对 Value 进行加权求和。即得到最终的 Attention 数值。 所以对应的公式可以写成： \[ Attention(Query, Source) = \sum_{i=1}^{L_x} Similarity(Query, Key_i) * Value_i \] 第二种解释： 软寻址 将Source 看做是存储器内存储的内容， 元素由 Key 和 Value 值组成。 当前有一个查询 Query。 通过 Query 和存储器内元素 key 进行相似性比较来寻址。 软寻址，指的是从每个 Key 中都会取出对应的 Value 值， 根据重要性，对 Value 进行加权求和。 1.4 注意力机制的三段式计算过程 注意力机制的三阶段计算过程 第一阶段： 根据 Query 和某个 \(Key_i\)， 计算两者的相似性或者相关性。 点积： \(Similarity(Query, Key_i)= Query \cdot Key_i\) Cosine 相似性： \(Similarity(Query, Key_i) = \frac{Query \cdot Key_i}{||Query|| \cdot ||Key_i||}\) MLP 网络： \(Similarity(Query, Key_i)=MLP(Query, Key_i)\) 第二阶段：对第一个阶段产生的分值，利用类似 SoftMax 的计算方法进行归一化， 同时能够突出重要元素的权重。 \[ a_i = Softmax(Sim_i) = \frac{e^{Sim_i}}{\sum_{j=1}^{L_x} e^{Sim_j}} \] 第三阶段： 利用权值系数，对 Value 进行加权求和。 \[ Attention(Query, Source) = \sum_{i=1}^{L_x} a_i \cdot Value_i \] 1.5 Self Attention 模型 Self-Attention 的可视化 理解 Self-Attention可以理解成 Source 和 Target 内容是一样的情况下的注意力机制。 Self-Attention可以捕获同一个句子中单词之间的一些句法特征或者语义特征。 Self-Attention能够更加容易捕获句子中长距离的相互依赖的特征。]]></content>
      <categories>
        <category>Deep Learning</category>
      </categories>
      <tags>
        <tag>Attention Mechanism</tag>
        <tag>注意力机制</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Attention Mechanism]]></title>
    <url>%2F2019%2F03%2F14%2FAttentionMechanism%2F%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[注意力机制 （一）. 一般的注意力机制的公式 \[ \begin{align} S^{l \times 1} &amp;= \tanh (H^{l \times m} W^{m \times n} +b^{n})U^{n \times 1} \\ \alpha^{l \times 1} &amp;= \frac{ \exp (S^{l \times 1}) }{ \sum\limits_{i=1}^{l} \exp （S_{i,1}^{l \times 1}）} \\ v &amp;= \sum\limits_{i=1}^l \alpha_{i, 1} H^{l \times m}_{i，：} \end{align} \] 在上面的公式中 上标表示的是符号对应的矩阵的形状， 下标指的是取这个矩阵中的具体某一个元素， 冒号表示选取那个维度的所有元素。 第一个公式表示的是打分函数的计算， 原始的输入 \(H^{L \times m}\) 表示为 $l m $ 的一个矩阵。 例如有 \(l\) 个词的文本，每个文本的词嵌入是 \(m\) 维； 每个时间步 RNN 的输出的合并，\(l\) 表示时间步的长度， \(m\) 表示每个时间步输入向量的维度。 首先将 \(H\) 经过一个 全连接层 (dense layer ， 就是两个矩阵相乘) 将 \(m\) 维的向量变换为 \(n\) 维的向量。再经过一个激活函数， 然后再经过一个全连接层。 得到\(S^{l \times 1}\) ，称为是对每个输入特征向量的打分。 类似的打分函数还有： \[ \begin{align} S^{l \times 1} &amp;= H^{l \times m}U^{m \times 1} \\ S^{l \times 1} &amp;= H^{l \times m}W^{m \times n} U^{n \times 1} \\ S^{l \times 1} &amp;= \tanh (H^{l \times m }) U^{m \times 1} \end{align} \] 简单一点理解就是将 输入 \(H^{l \times m}\) 通过矩阵运算得到一个 \(S^{l \times 1}\) 的矩阵， 这个矩阵中的每个值代表了对应位置特征向量的重要程度。 公式中的\(W, b, U\) 都是权重，在注意力网络中通过随机初始化，然后通过反向传播进行训练的。 第二个公式表示的是一个 Softmax 函数。 将得到的 \(S^{l \times 1}\) 看做一个向量， 那么这就是对这个向量的归一化的过程。 第三个公式表示根据第二步确定的每个特征向量的重要程度，对原始输入 \(H\) 中的特征向量进行加权求和。 举个例子： 输入 \(H = [[1,2,3], [2,2,2], [1,1,1], [2,1,2]]\) ，\(W, b, U\) 分别初始化为 \(W = [[1,1], [2,2], [1,2]]， b=[[1, 1]], U=[[2], [1]]\) code 123456789import numpy as npH = np.array([[1,2,3], [2,2,2], [1,1,1], [2,1,2]])W = np.array([[1,1], [2,2], [1,2]])b = np.array([[1, 1]])U = np.array([[2], [1]])S = np.dot(np.dot(H, W)+b, U)alpha = np.exp(S)/sum(np.exp(S))res = np.dot(np.array([[1,1,1,1]]), H* alpha) (二). seq2seq 中的 Attention 先写一遍 LSTM 的计算公式 \[ \begin{align} \left[ \begin{array} i_t \\ f_t \\o_t \\ \hat{C_t} \end{array} \right] &amp;= \left[ \begin{array} \\ \sigma \\ \sigma \\ \sigma \\ \tanh \end{array} \right] (W \cdot [h_{t-1}, x_t] + b) \\ C_t &amp;= f_t* C_{t-1} + i_t * \hat{C_t} \\ h_t &amp;= o_t * C_t \end{align} \] GRU 的公式就不写了，也差不多都是类似的结构。 一般的 seq2seq 结构是 \[ \begin{align} \text{Source} &amp;= &lt;x_1, x_2, ..., x_m&gt; \\ \text{Target} &amp;= &lt;y_1, y_2, ..., y_n&gt; \\ C &amp;= F(x_1, x_2, ..., x_m) \\ y_i &amp;= \mathcal{G} (\mathbf{C}, y_1, y_2, ..., y_{i-1}) \end{align} \] 引入了注意力机制的结构是 \[ \begin{align} y_i &amp;= \mathcal{G} (\mathbf{C_i} , y_1, y_2, ..., y_{i-1}) \\ C_i &amp;= \sum_{j=1}^{L_x} a_{ij} h_j \end{align} \] 自己的理解 引入了注意力结构的 seq2seq 结构中加入了 \(C_i\)， 这里的 \(C_i\) 是注意力机制中最后得到的向量， 对应与 (一) 中的 \(v\) 。 因此解码端的序列长度为多少就重复了多少次 (一) 中的注意力。 每个 \(C_i\) 一般会和 LSTM（或者其它的RNN） 中的隐状态 \(C_t\) 进行相加或者拼接。 而没有引入注意力的 seq2seq 只有编码端最后时刻的隐状态一个。 (三) . Attention 更加普遍的定义 \[ Attention(Q, K, V) = softmax(\frac{QK^T}{ \sqrt{d_k} }) V \] ​ 这个定义来源于 Attention is All You Need 这篇论文。 \(V\) 指的是 Values, 也就是所有的特征的集合，例如对于RNN 中，我们的目标是关注所有的 RNN 的输出，那么\(V\) 的第 \(i\) 行表示第 \(i\) 时刻的输出。我们假设每一个 value 都一个键与之对应。这个 \(key\) 值是用来确定对应的 \(value\) 的一组值， 也就是说我们能够通过 \(key\) 来找出对应的 \(value\) 值是多少。 同时我们需要通过 \(key\) 值来确定对应的 \(value\) 在文本中的重要程度。 我们需要通过一个 query 来查询对应 \(key\) 值的 \(value\) 的重要程度。 因此在公式中 \(Q\) 表示的是一组 \(query\) 的集合， 矩阵中的一行代表的是一条查询。 \(QK^T\) 表示矩阵乘法， 那么我们得到的任意一个行向量来自于 对应的一个 query 与所有 \(K\) 中的行向量做点乘(注意，这里是 \(K\) 中的行向量，对应于 \(K^T\) 中的列向量)。$softmax $ 表示对这个行向量做归一化处理。 \(\sqrt{d_k}\) 表示的是对相应的值缩小。最后和 \(V\) 做矩阵相乘得到的结果中任意一行的结果表示的是一条查询对应的注意力得到的结果。 ​ 当 \(key\) 和 \(value\) 都是一样的时候， 并且打分函数是 \(H^{l \times m}U^{m \times 1}\) 的情况下，这个定义其实和 \((一)\) 中的内容是一样的。 只是每一条 query 对应着 \((一)\) 中的一次操作。 ​ 这里的 \(K\) 和 \(V\) 可以不一样，但是在大部分情况下都是一样的。 (四). Self-Attention ​ 在 \((一)\) 中的表示方法中 \(K\) 和 \(V\) 都是原始的输入 即 \(H\) , \(Q\) 对应着 \(W\) 。 当 \(K=V= Q\) 的时候，我们认为这是一种自注意力， 也就是\(Q\) 中的一条查询和对应 \(K\) 中的一条值进行点积， 这个点积的含义就是通过自身与自身的比较，来确定自身的重要程度。]]></content>
      <categories>
        <category>Deep Learning</category>
      </categories>
      <tags>
        <tag>Attention Mechanism</tag>
        <tag>注意力机制， self-attention</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Batch Normalization]]></title>
    <url>%2F2019%2F03%2F14%2FBatchNormalization%2F</url>
    <content type="text"><![CDATA[1. Batch Normalization 1.1 Batch Normalization 的做法 输入： mini-batch 输入 \(x: B={x_1, ...., x_m}\) 输出： 规范化后的网络响应 \({y_i = BN_{\gamma, \beta}(x_i)}\) - 计算 批数据的均值和方差 \[ \begin{align} u_B &amp;= \frac{1}{m} \sum_{i=1}^m x_i \\ \sigma_{B}^2 &amp;= \frac{1}{m} \sum_{i=1}^m (x_i -u_{B})^2 \end{align} \] - 规范化 \[\hat{x_i} = \frac{x_i - u_B}{\sqrt{\sigma_B^2 + \epsilon } }\] - 尺度变换和偏移 \[y_i = \gamma \hat{x_i} + \beta\] 1.2 Batch Normalization 的作用 是一种对抗梯度消失的有效手段 （将偏移0附加较大的数据分布拉回0均值1方差的分布中） 数据的分布一直处于敏感的区域，相当于不用考虑数据分布的变化。 因为数据本身的分布本身不是0均值1方差的，通过最后一步的偏移能够保证模型的非线性表达能力。 1.3 预测时的均值和方差怎么求 问题来源： 因为在预测的时候通常是单个样本进行预测的，因此没有所谓的批。 - 计算方法 \[ \begin{align} E[x] &amp;= E_{B}[u_B] \\ Var[x] &amp;= \frac{m}{m-1} E_{B} [\sigma_B^2] \\ y &amp;= \frac{\gamma}{\sqrt{Var[x] + \epsilon}} \cdot x + (\beta - \frac{\gamma E[x]}{\sqrt{Var[x] + \epsilon}}) \end{align} \] 其中 均值和方差都是通过在训练集上得到的均值和方差进行求期望得到的。]]></content>
      <categories>
        <category>Deep Learning</category>
      </categories>
      <tags>
        <tag>Batch Normalization</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[主成分分析方法]]></title>
    <url>%2F2019%2F01%2F05%2F%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[主成分分析（Principal Component Analysis ） 什么是主成分 ​ 对高维的数据点进行变换到另一组低纬的空间中， 并且使得数据点在低纬的空间中也能够表达出原始数据的意义。 就称为低纬空间中的对应变换坐标所包含的信息为主成分。 例如三维映射到二维的 x轴和y轴。那么x轴和y轴所包含的信息为我们找到的主成分。 主成分分析的步骤 对数据点进行中心化处理(为了让投影后的均值也为0，方便后面的计算) 写出变换后的方差。（投影后方差最大） \[ \begin{align} D(x) &amp;= \frac{1}{n} \sum\limits_{i=1}^n (x_i^T w-0)(x_i^Tw-0) \\ &amp;= \frac{1}{n} \sum\limits_{i=1}^n w^T x_i x_i^T w \\ &amp;= w^T (\frac{1}{n} \sum\limits_{i=1}^n x_i x_i^T) w \end{align} \] 目标函数为： \[ \begin{align} \max &amp;\quad w^T \Sigma w \\ s.t &amp;\quad w^Tw = 1 \end{align} \] 引入拉格朗日函数函数 \[ L(w, \lambda) = w^T \Sigma w + \lambda (1-w^Tw) \] 求 \(\frac{ \partial L }{ \partial w}\) 与 \(\frac{\partial L}{ \partial \lambda}\) \[ \Sigma w = \lambda w \] 即求对应的特征值 对协方差矩阵进行特征值分解，将特征值按从大到小的顺序排列 取特征值前 \(d\) 大对应的特征向量 \(w_1, w_2, ..., w_d\) 通过以下映射将 \(n\) 维样本映射到 \(d\) 维 \[ x_l&#39; = \left[ \begin{align} w_1^T x_l \\ w_2^T x_l \\ ..... \\ w_d^T x_l \end{align} \right] \] 信息占比为： \(\eta = \sqrt{ \frac{\sum\limits_{i=1}^d \lambda_i^2}{ \sum\limits_{i=1}^n \lambda_i^n } }\) 主成分分析方法的两种解释 最大方差的解释 最小平方误差（最小化样本点到直线的距离平方和, 百面机器学习第一版p79）]]></content>
      <categories>
        <category>ML</category>
      </categories>
      <tags>
        <tag>PCA， 主成分分析方法，降维</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[提升方法]]></title>
    <url>%2F2019%2F01%2F05%2Fboost_bagging%2Fboosting%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[提升方法 介绍 强可学习与弱可学习 强可学习 : 一个概念（类）,存在一个多项式的学习算法能够学习他，并且正确率很高，则这个概念是强可学习的。 弱可学习：一个概念（类）,存在一个多项式的学习算法能够学习他，但是学习的正确率只比随机猜测略好，那么这个概念就是弱可学习的。 强可学习和弱可学习是等价的， 一个概念是强可学习的充分必要条件是这个概念是弱可学习的。 提升方法的由来 在学习中， 如果发现了 &quot;弱学习算法&quot; 那么能够将它提升为 &quot;强学习算法&quot;。 提升方法的两个问题 在每一轮如何改变训练数据的权重值或概率分布？ 如何将弱分类器合成一个强分类器？ 注： 提升方法实际采用加法模型（即基函数的线性组合）与前向分布算法。 所以对于上面的两个问题我们可以改为 （1）确定损失函数，如何求的基本分类器，也就是说输入数据变了训练得到的基本分类器也不一样了 （2）怎么确定基本分类器在合成整个分类器中基本分类器对应的权重。 加法模型与前向分布算法 加法模型： \[ f(x) = \sum\limits_{m=1}^M \beta_m b(x; \gamma_m) \] 其中， \(b(x; \gamma_m)\) 是基函数， \(\gamma_m\) 是基函数的参数，\(\beta_m\) 是基函数的参数。 也就是将一些基本分类器按照权值相加得到一个分类器。 前向分布算法 作用 学习加法模型, 可以理解为是给定训练数据和损失函数的条件下，学习加法模型 \(f(x)\) 成为经验风险最小化的问题。 \[ \min_{\beta_m, \gamma_m} \sum\limits_{i=1}^N L \left( y_i, \sum\limits_{i=1}^N \beta_m b(x_i; \gamma_m) \right) \] 这是一个复杂的问题，因此我们可以用前向分布算法从前往后，每一步只学习一个基函数与系数，逐步逼近优化目标的函数式子。 步骤 输入: 数据集 \(T=\{ (x_1, y_1), (x_2, y_2), ..., (x_N, y_N) \}\) ； 损失函数 \(L(y, f(x))\); 基函数集 \(\{ b(x; y) \}\) 输出：加法模型 \(f(x)\) 初始化 \(f_0(x) = 0;\) 对 \(m =1,2,3..., M\) \((\beta_m, \gamma_m) = \arg \min\limits_{\beta, \gamma} \sum\limits_{i=1}^N L( y_i, f_{m-1}(x_i) + \beta b(x_i; \gamma))\) \(f_m(x) = f_{m-1}(x) + \beta_m b(x; \gamma_m)\) 得到加法模型 \[ f(x) = f_M (x) = \sum\limits_{m=1}^M \beta_m b(x; \gamma_m) \] AdaBoost ​ AdaBoost 通过在每次训练过程中根据当前分类器对数据分类是否正确，调整训练数据的权重值。 通过当前分类器在训练数据集上的分类精度判断当前分类器的权重，最后将所有分类器进行加权求和得到最终的分类器。 AdaBoost 的计算流程 初始数据权值： \(w_{1i} = \frac{1}{N}, i=1,2,...,N\) 加权误差： \(e_m = \sum\limits_{i=1}^N P(G_m(x_i) \neq y_i) = \sum\limits_{i=1}^N w_{m_i} I( G_m(x_i) \neq y_i)\) 其中 \(G_m (x)\) 表示基本分类器，结果为-1或1。 分类器权值系数： \(\alpha_m = \frac{1}{2} \log \frac{1-e_m}{e_m}\) 数据权值分布： \[ \begin{align} w_{m+1, i} &amp;= \frac{w_{mi}}{z_m} \exp(-\alpha_m y_i G_m (x_i)), i=1,2,...,N \\ Z_m &amp;= \sum\limits_{i}^N w_{mi}\exp(-\alpha_m y_i G_m(x_i)) \end{align} \] 当前分类器： \(f_m (x) = \sum\limits_{i=1}^M \alpha_m G_m (x)\) 停止条件： 当前分类器\(f_m(x)\) 的误差是否小于某个指定的值。 分类器权值系数和数据权值分布的说明 权值系数: 分类误差越大，权值越小， \(\frac{1}{2}\) 是一个分界点，小于 0.5 时大于0， 大于0.5时小于0。 数据权值分布： 如果正确分类权值为 \(\frac{w_{mi}}{ez_m}\) 错误分类权值为 \(\frac{ew_{mi}}{z_m}\) 。说明错误分类的数据在下一个分类器中的重要程度在不断的提升，正确分类的数据的重要程度在下降。 优缺点 优点：可以充分利用不同分类算法的优势进行建模，也可以将同一算法的不同设置进行组合。 缺点： 只支持二分类， 多分类需要借助 one-versus-rest 思想。 说明 AdaBoost 是前向分布算法的特列，模型由基本分类器组成的加法模型， 损失函数是指数损失函数。 提升树 ​ 提升方法采用的式加法模型（即基函数的线性组合）与前向分布算法，以决策树为基函数的提升方法。这里的决策树是只有两个节点叶节点的简单决策树，即所谓的决策树桩。 类别 分类： 采用二叉分类树作为基函数，损失函数采用的是指数损失函数，可以将分类决策树视为 AdaBoost 的基本分类器为决策树的一种特殊情况。 回归： 采用二叉回归树作为基函数。 回归问题的提升树算法 输入： 训练数据集 \(T = \{ (x_1, y_1), (x_2, y_2), ..., (x_N, y_N)\}\) 输出: 提升树 初始化 \(f_0(x) = 0\) 对 \(m=1,2,...,M\) 计算残差 \[ \begin{align} T(x; \theta) &amp;= \sum\limits_{j=1}^T c_j I(x \in R_j) \\ r_{mi} &amp;= y_i - f_{m-1}(x_i), i=1,2,...,N \end{align} \] 拟合残差 利用回归树拟合残差 \(r_{mi}\), 得到 \(T(x; \theta_m)\)。 更新 : \(f_m(x) = f_{m-1}(x) + T(x; \theta_m)\) 得到回归问题的提升树 \(f_M(x) = \sum\limits_{m=1}^M T(x; \theta_m)\) 梯度提升方法 ​ 当采用前向分布算法求解加法模型的时候，如果损失函数是平方损失或者指数损失函数的时候，每一步的优化都很简单。分别对应于残差与AdaBoost 中对训练数据权重的调节。 但是对于一般的损失函数，每一步的优化比较困难(为什么比较困难，不能用残差吗？)。 因此提出了梯度提升算法。 ​ 这种方法关键在于利用损失函数的负梯度在当前模型中的值作为回归问题梯度提升算法中的残差的近似值，拟合一个回归树。 梯度提升算法 输入: 训练数据集 \(T= \{ (x_1, y_1), (x_2, y_2),...,(x_N, y_N) \}\), 损失函数为 \(L(y, f(x))\)。 输出: 回归树 \(\hat{f(x)}\)。 初始化 \[ f_0(x) = \arg \min\limits_c \sum\limits_{i=1}^N L(y_i ,c) \] 对 \(m =1,2,...,M\) 对 \(i=1,2,...,N\) 计算 \[ r_{mi} = - \left[ \frac{\partial L(y_i, f(x_i))}{\partial f(x_i)} \right]_{f(x) = f_{m-1}(x)} \] 对 \(r_{mi}\) 拟合一个回归树，得到第 \(m\) 棵树的叶节点区域 \(R_{mj}, j=1,2,...,J\)。 对 \(j=1,2,...,J\), 计算 \[ c_{mj} = \arg \min\limits_{c} \sum\limits_{x_i \in R_{mj} L(y_i, f_{m-1}(x_i)+c)} \] 更新 \(f_m(x) = f_{m-1}(x) + \sum\limits_{j=1}^J c_{mj} I(x \in R_{mj})\) 得到回归树 \[ \hat{f(x)} = f_M(x) = \sum\limits_{m=1}^M \sum\limits_{j=1}^J c_{mj} I(x \in R_{mj}) \] 对于平方损失函数，负梯度就是残差，对于一般的损失函数，它就是残差的近似值。 梯度提升树（GBDT, Gradient Boosting Decison Tree） 介绍 提升树 + 梯度提升 弱学习器限定只能使用 CART 树 可以用来做分类也可以用来做回归 GBDT 回归算法 和提升方法中的步骤是一样的， 只是限定了弱学习器（基函数）只能采用 CART 树。 GBDT 分类算法 因为 GBDT 做分类的时候样本输出不是连续的值，因此可以拟合预测的概率值: hk。 可以采用指数损失函数或者对数损失函数， 当采用指数损失函数的时候退化为 AdaBoost 算法。 对于对数损失函数又有二元分类和多分类的区别。 二元 GBDT 分类算法 损失函数为： \(L(y, f(x)) = \log(1+exp(-yf(x)))\) 其中 \(y \in \{-1, +1\}\) 负梯度为：\(r_{ti} = - \frac{\partial L(y_i, f(x_i))}{ \partial f(x_i)} = \frac{y_i}{1+ \exp(y_i f(x_i))}\) 叶节点的最佳负梯度拟合值是： \(c_{tj} = \arg\min\limits_{c} \sum\limits_{x_i \in R_{tj}} log(1+ \exp(-y_i (f_{t-1}(x_i)+c)))\) 最佳负梯度的近似值是： \(c_{tj} = \frac{ \sum\limits_{x_i \in R_{tj}} r_{tj} }{ \sum\limits_{x_i \in R_{tj} } |r_{ti}| (1-|r_{ti}| ) }\) 多元 GBDT 分类算法 损失函数： \(L(y, f(x)) = - \sum\limits_{k=1}^K y_k \log p_k(x)\) 预测为第 \(k\) 类的表达式是： \(p_k (x) = \frac{ \exp(f_k (x)) }{ \sum\limits_{l=1}^K \exp(f_l(x)) }\) 负梯度： $r_{til} = -{f_k (x) = f{l, t-1} (x)} =y_{il} - p_{l,t-1}(x_i) $ 最佳负梯度拟合值是： $ c_{tjl} = {c{jl}} {i=0}^m {k=1}^K L(y_k, L(y_k, f_{t-1, l}(x) + {j=0}^J c{jl} I(x_i R_{tjl}) )) $ 最佳负梯度的近似值： $ c_{tjl} = $ GBDT 的正则化 添加正则化项（或步长） \[ f_k(x) = f_{k-1}(x) + vh_k (x) \] 通过子采样（无放回），只用小部分样本去做决策树的拟合 （具体怎么做？） 对CART 回归树做正则化剪枝 XGBoost XGBoost 是陈天奇等人开发的一个开源机器学习项目， 高效的实现了 GBDT 算法，并进行了算法和工程上的许多改进。 GBDT 算法基于经验损失函数的负梯度来构造新的决策树， 只是在决策树构造完成后再进行剪枝。 而 XGBoost 在决策树构建阶段就加入正则化项。 \[ L_t = \sum\limits_i L(y_i, F_{t-1}(x_i) + f_t(x_i)) + \Omega (f_t) \\ \Omega (f_t) = \gamma T + \frac{1}{2} \sum\limits_{j=1}^T w_j^2 \] 其中 \(F_{t-1}(x_i)\) 表示现有的 \(t-1\) 棵树的最优解，\(T\) 为第\(t\) 棵树的叶子节点的数量。 \(w_j\) 表示第 \(j\) 个节点的预测值。 对该损失函数在 \(F_{t-1}\) 处进行二阶泰勒展开可以推导出： \[ L_t \approx \hat{L_t} = \sum\limits_{j=1}^T \left[ G_jw_j + \frac{1}{2} (H_j + \lambda)w_j^2 \right] + \gamma T \] 其中 $G_j = {i I_j } {F_{t-1}} l(y_i, F_{t-1}(x_i)) $ , \(H_j = \sum\limits_{i \in I_j } \bigtriangledown _{F_{t-1}}^2 l(y_i, F_{t-1}(x_i))\) 通过令损失函数相对于 \(w_j\) 的导数为 0可以求出在最小化损失函数的情况下各个叶子节点上的预测值。 \[ w_j ^* = -\frac{G_j}{H_j + \lambda} \] 我们可以将预测值带入损失函数中可求得损失函数的最小值是： \[ \hat{L_t^*} = -\frac{1}{2} \sum\limits_{j=1}^T \frac{ G_j^2 }{H_j + \lambda} + \gamma T \\ \] 容易计算出分裂前后损失函数的差值为： \[ Gain = \frac{G_L^2 }{H_L + \lambda} + \frac{G_R^2}{H_R + \lambda} - \frac{(G_L + G_R)^2}{H_L + H_R + \lambda} - \gamma \] XGBoost 采用这个差值作为准则进行决策树的构造（和CART, C4.5， ID3是一样的，只是换称了这个指标）。 XGBoost 和 GBDT 的区别和联系 GBDT 是机器学习算法， XGBoost 是该算法的工程实现。 在使用 CART 树作为基分类器时， XGBoost 显式的加入了正则化项，上面已经说明了，相当于从新定义了一个构造树的指标。 能够控制模型的复杂度，有利于防止过拟合，从而提高模型的泛化能力。 GBDT 只使用了代价函数的一阶导数信息，XGBoost 使用了二阶导数的信息。 GBDT 采用CART 作为基分类器， XGBoost 采用多种基分类器包括了 线性分类器。 XGBoost 支持子采样。 XGBoost 对数据的缺失值能够进行处理。 XGBoost 的并行能力 在特征排序上进行了处理，采用了 block 的结构 （具体怎么做的？） 计算各个特征的增益是可以进行并行的。 近似直方图算法？]]></content>
      <categories>
        <category>ML</category>
      </categories>
      <tags>
        <tag>AdaBoost</tag>
        <tag>GBDT</tag>
        <tag>提升树</tag>
        <tag>前向分布算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Word2vec 优化方法之 Negative Sampling]]></title>
    <url>%2F2018%2F12%2F26%2FWord2vec%2FWord2vecNegativeSampling%2F</url>
    <content type="text"><![CDATA[Negative Sampling 1. 为什么要采用 Negative Sampling? 符号说明： |符号|含义| |----|----| |\(n\)|词表的大小| |\(m\)|词向量的长度| |\(x_n\)| \(n\) 维的 one-hot 表示的词向量| 个人的理解： 原始的 Word2vec 模型可以写成 \(\text{Softmax}(x_n \times W_{n \times m} \times W_{m \times n})\)。从输入层到输出层的变换 \(x_n \times W_{n \times m}\) 可以仅仅看做是一个查表的过程，因为 \(x_n\) 是 one-hot 的表示所以并不费时间。 在原始的 Word2vec 中从隐藏层到输出层的变化 \(\hat{x_m} \times W_{m\times n}\) 中在每一次的训练中需要对 \(W_{m \times n}\) 中的每一个参数做运算(无论是在前向计算或者反馈的过程中)， 即使采用了 Hierarchical Softmax 的方法，如果遇到一个生僻的词（这个词在 huffman 树的非常深的树叶节点处）作为中心词， 那么在每次训练过程中，需要进行的二元逻辑回归次数也是非常多的。 因此有必要找一种方法，这种方法能够使得每次训练的过程中只需要对一部分的参数进行训练，从而减少计算量，加快训练过程。Negative Sampling 就是一种这样的方法。 2. Negative Sampling 介绍 ​ 负采样的方法通过随机的采取中心词的若干个负样本，然后通过对正样本和负样本的二元逻辑回归结果取极大似然作为目标对这些二元逻辑回归中的参数进行训练。也就是说，对于同一组的训练数据。我们只对这些负样本词和真的中心词为中心词的二元逻辑回归中的参数进行了训练。 ​ 更通俗的将，我们对每个中心词都构造了一个二元逻辑回归，这个二元逻辑回归用于判断当前输入的上下文单词是否为该中心词的上下文。 那么如果词表的大小为\(V\) 那么我们需要构造 \(V\) 个二元逻辑回归。 如果我们有一个中心词 \(w_0\) 以及其对应的上下文单词 \(\text{context}(w)\)，同时我们选取了 \(n\) 个负样本为\(w_1, w_2, ...., w_n\)。 那么对应的目标函数就是 ： \[ L = \sum\limits_{i=0}^n y_i \log (\sigma (x_{w_0}^T \theta^{w_i} ) ) + (1-y_i)\log (1- \sigma(x_{w_0}^T \theta^{w_i})) \] 其中的 \(x_{w_0} ^T\) 表示 \(w_0\) 的上下文的输入。例如在 CBOW 就是上下文词向量取算术平均之后的结果， 在 Skip-gram 中就是上下文的单个词向量。当 \(i=0\) 的时候 \(y_i=1\) 否则为 0。 3. 负采样的方法 先将单位1均匀的划分为 \(M\) 份。\(M&gt;&gt;V\), \(V\) 表示词表的大小。 计算每个单词占据整个词表的长度： \[ len(w) = \frac{\text{count}(w)^{3/4}}{\sum\limits_{u \in \text{vocab} } \text{count}(u)^{3/4}} \] 根据计算得到的长度，将单位1中的小份分给每个单词。 随机在单位1中生成 \(n\) 个点，这些点落在哪个单词所属的区域那就选这些单词作为负样本。 4. CBOW 和 Skip-gram 模型的算法步骤 4.1 CBOW 模型 输入：基于 CBOW 的语料训练样本，词向量的维度大小 \(Mcount\)，CBOW的上下文大小是\(2c\),步长\(\eta\), 负采样的个数\(neg\)。 输出：词汇表每个词对应的模型参数\(\theta\)，所有的词向量\(x_w\)。 1.随机初始化所有的模型参数\(\theta\)，所有的词向量\(w\)； 对于每个训练样本\((context(w_0),w_0)\),负采样出\(neg\)个负例中心词\(w_i,i=1,2,...neg\)； 进行梯度上升迭代过程，对于训练集中的每一个样本\((context(w_0),w_0,w_1,...w_{neg})\)做如下处理: \(e=0\), 计算 \(x_{w_0} = \frac{1}{2c} \sum\limits_{i=1}^{2c} x_i\)。 for i to neg, 计算: \[ f = \sigma(x_{w_0}^T \theta^{w_i}) \\ g = (y_i -f)\eta \\ e = e + g^{\theta^{w_i}} \\ \theta^{w_i} = \theta^{w_i} + g x_{w_0} \] 对于\(context(w)\)中的每一个词向量\(x_k\)(共\(2c\)个)进行更新： \[ x_k = x_k + e \] 如果梯度收敛，则结束梯度迭代，否则回到步骤3继续迭代。 4.2 Skip-Gram模型 输入：基于 CBOW 的语料训练样本，词向量的维度大小 \(Mcount\)，CBOW的上下文大小是\(2c\),步长\(\eta\), 负采样的个数\(neg\)。 输出：词汇表每个词对应的模型参数\(\theta\)，所有的词向量\(x_w\)。 随机初始化所有的模型参数\(θ\)，所有的词向量\(w\) 对于每个训练样本\((context(w_0),w_0)\),负采样出\(neg\)个负例中心词\(w_i,i=1,2,...neg\) 进行梯度上升迭代过程，对于训练集中的每一个样本\((context(w_0),w_0,w_1,...w_{neg})\)做如下处理： for i = 1 to 2c: \(e\) = 0; for j =0 to neg. 计算： \[ f = \sigma(x_{w_0}^T \theta^{w_j}) \\ g = (y_j -f)\eta \\ e = e + g^{\theta^{w_j}} \\ \theta^{w_j} = \theta^{w_j} + g x_{w_0} \] 词向量更新 \[ x_ {w_{0i}} = x_{w_{0i}} + e \] 如果梯度收敛，则结束梯度迭代，算法结束，否则回到步骤a继续迭代。]]></content>
      <categories>
        <category>ML</category>
      </categories>
      <tags>
        <tag>Negative Sampling， Word2vec</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Word2vec 优化方法之 Hierarchical Softmax]]></title>
    <url>%2F2018%2F12%2F26%2FWord2vec%2FWord2vecHierarchicalSoftmax%2F</url>
    <content type="text"><![CDATA[Hierarchical Softmax 来源 ### 1. 为什么要采用层次Softmax? - 普通的 word2vec 可以写成 \(\text{Softmax}( x_{n} \times W_{n \times m} \times W_{m \times n} )\) 。 - 从输入层到隐藏层的变换 \(x_n \times W_{n \times m}\) 因为输入是 one-hot 的表示方法， 因此这个变换只需要选出 1 所在的那一行参数，因此时间复杂度 \(O(m)\) 的。 - 从隐藏层到输出层的变换 \(\hat{x_m} \times W_{m \times n}\), 其中 \(\hat{x_m}\) 表示隐藏层的神经元（向量）。 需要考虑 \(m \times n\) 个参数。因此 hierarchical softmax 用于减少隐藏层到输出层的计算复杂度。 2.层次Softmax 的做法？ 对词表中的所有单词按照其在文本库中的出现的频率构造一颗 赫夫曼树。 赫夫曼数的叶结点都表示一个单词。 每个根结点表示概率值。根结点的概率值为1。 在赫夫曼树的每个结点都带有参数 \(\theta_i\), \(\theta_i \in R^{m \times 2}\) \(\theta_i\) 用来计算隐藏层在该结点的时候的输出概率, 采用的是 Sigmoid 函数。 \(\sigma (\hat{x_m} \theta_i )\) 当这个概率值大于 0.5 的情况下，可以人为的定义其属于左结点或者右结点。 因此 采用 hierarchical softmax 在隐藏层到输出层的参数总量大约为 $ 2m _2(V) $ 这个数量比原本的 参数量 \(m \times n\) 少的多。 3.基于 hierarchical softmax 的模型梯度计算。 符号说明 | 符号 | 含义 | | ---- | ---- | |\(w\)|输入的词向量| |\(x_w\) |隐藏层的向量（Huffman tree 根结点的词向量）| |\(l_w\)| 从根结点开始到 \(w\) 的叶子结点，包含的结点总数是 \(l_w\) | |\(d_j^w\)| \(d_j^w \in \{0, 1\}\), 表示第 \(j\) 个结点的赫夫曼编码， \(j=2,3,...,l_w\) 因为根结点没有对应的编码，所以 \(j\) 是从2开始的。| |\(\theta_{j}^w\)| 表示第 \(j\) 个结点的参数，该参数与 \(\sigma(x_w \theta_{j}^w)\) 用来表示下一个结点是左结点还是右结点的概率。\(j=1,2,...,l_w-1\) 因为叶结点是不含参数的所以到 \(l_w-1\)| 为止。| 过程 在 huffman tree 左结点或右结点的概率是： \[ P(d_j^w|x_w, \theta_{j-1}^w ) = \left\{ \begin{align} &amp;\sigma(x_w^T \theta_{j-1}^w) &amp;d_j^w = 0\\ &amp;1-\sigma(x_w^T \theta_{j-1}^w) &amp;d_j^w = 1 \end{align} \right. \] \(w\)对应的赫夫曼编码的似然函数为： \[ \prod_{j=2}^{l_w} \sigma(x_w^T \theta_{j-1}^w)^{1-d_j^w} (1-\sigma(x_w^T \theta_{j-1}^w )^{d_j^w}) \] 对数似然 \[ \begin{align} L &amp;= \log \prod_{j=2}^{l_w} P(d_j^w | x_w, \theta_{j-1}^w) \\ &amp;= \sum\limits_{j=2}^{l_w} [ (1-d_j^w)\log( \sigma(x_w^T \theta_{j-1}^w) ) + d_j^w \log( 1- \sigma(x_w^T \theta_{j-1}^w))] \end{align} \] 求导 \[ \begin{align} \frac{\partial L }{\partial \theta_{j-1}^w} &amp;=(1-d_j^w) \frac{\sigma(x_w^T \theta_{j-1}^w) (1- \sigma(x_w^T \theta_{j-1}^w))}{\sigma(x_w^T \theta_{j-1}^w)} x_w^T - d_j^w \frac{ \sigma(x_w^T \theta_{j-1}^w) (1- \sigma(x_w^T \theta_{j-1}^w))}{1- \sigma(x_w^T \theta_{j-1}^w)}x_w^T \\ &amp; = (1-d_j^w - \sigma(x_w^T \theta_{j-1}^w))x_w \\ \text{同理可得：} \\ \frac{\partial L }{\partial x_w} &amp;= \sum\limits_{j=2}^{l_w} (1-d_j^w - \sigma(x_w^T \theta_{j-1}^w)) \theta_{j-1}^w \end{align} \] 4. 基于 Hierarchical Softmax 的 CBOW 模型 符号说明 符号 含义 \(c\) CBOW模型中上下文的大小是 \(2c\) \(x_i\) \(x_w\) 的第 \(i\) 个上下文单词 \(eta\) 步长、学习率 对每个训练样本的训练过程 求和： $ _{i=1}^{2c} x_i $。 CBOW 需要将上下文的词向量通过加和转化为一个词向量。 e=0: 用于对每个结点的梯度进行加和，因此对 \(x_w\) 进行更新的时候用到了这个。 对 \(j=2,3...,l_w\) 分别计算对应结点参数的梯度 \[ \begin{align} f &amp;= \sigma(x_w^T \theta_{j-1}^w) \\ g &amp;=(1-d_j^w-f)\eta \\ e &amp;=e+g\theta_{j-1}^w \\ \theta_{j-1}^w &amp;= \theta_{j-1}^w + gx_w \end{align} \] 对 \(x_i\) 进行梯度更新。 \[ x_i = x_i + e\] hk: 注意这里的 \(e\) 严格来说应该是对 \(x_w\) 求得的梯度，但是 每个 \(x_i\) 和这个梯度相比只差了个常数的倍数 \(\frac{1}{2c}\)。 因此这里直接用 \(e\) 来更新 \(x_i\)。 直到梯度收敛的时候结束，否则继续迭代 5. 基于 Hierarchical Softmax 的 skip-gram 模型 训练过程中采用上下文来预测中心词 skip-gram 的核心思想是通过 中心词对上下文进行预测也就是 \(P(x_i|x_w), i=1,2,...,2c\)。因为上下文是相互的，因此我们在期望 \(P(x_i|x_w)\) 最大的同时也是要求 \(P(x_w | x_i)， i=1,2,...,2c\) 最大。 因为对 \(P(x_w |x_i)\) 求期望最大的过程我们同时对2c个单词进行更新，能够使整体的迭代更加均衡。所以，skip-gram 相当于对 2c个输出进行迭代更新。 对于每一个训练样本 \((x_w, x_i)\)进行迭代 e=0 对于 \(j\)从1到 \(l_w\): \[ \begin{align} f &amp;= \sigma(x_i^T \theta_{j-1}^w) \\ g &amp;= (1-d_j^w -f)\eta \\ e &amp;= e + g\theta_{j-1}^w \\ \theta_{j-1}^w &amp;= \theta_{j-1}^w + g_{x_i} \end{align} \] \(x_i = x_i + e\) 如果梯度收敛就，结束梯度迭代，算法结束，否则，继续。 6. 一些个人的理解 在仅仅考虑训练的过程，我们会发现在引用了hierarchical softmax 的word2vec 中 skip-gram 和 CBOW 的输出都是对中心词的预测， 只不过 CBOW一次性 的输出 2c 个词然后在隐藏层进行了一个 加和构成一个向量，然后来预测对应的输出，而skip-gram 一次只输入一个单词，来预测对应的输出，因此我们可以理解为 CBOW一次训练更新了 2c个词向量对应的权重值，而 skip-gram一次只更新对应一个单词的权重。 或者可以理解为 CBOW用上下文的2c个单词来预测中心词，而skip-gram 利用上下文的每一个单词来预测中心词。]]></content>
      <categories>
        <category>ML</category>
      </categories>
      <tags>
        <tag>Hierarchical Softmax， Word2vec</tag>
        <tag>层次Softmax</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[拉格朗日函数求解最优化问题,KKT条件]]></title>
    <url>%2F2018%2F12%2F25%2FSVM%2F%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E5%87%BD%E6%95%B0%E6%B1%82%E8%A7%A3%E4%BC%98%E5%8C%96%E9%97%AE%E9%A2%98%E4%BB%A5%E5%8F%8Akkt%E6%9D%A1%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[拉格朗日函数求解最优化问题，KKT条件 注： KKT 条件是用来求解含有不等式约束的优化问题的一种方法。 满足 KKT 条件， 是某点为非线性规划问题的极值点的必要条件（不满足KKT条件必然不是极值点，满足KKT条件但未必是极值点 ）。 当所求得非线性规划问题是凸规划， 那么 KKT 条件也是充分条件（满足KKT条件则必然是原问题的极值点）。 优化问题求解方法的总结（只考虑凸优化问题） 对于无约束的优化问题，直接令梯度等于0求解。 对于含有等式约束的优化问题，拉格朗日乘子法，构造拉格朗日函数，令偏导为0求解。 对于含有不等式约束的优化问题，同样构造拉格朗日函数，利用KKT条件求解。 对于含有约束的优化问题，还可以转化为对偶问题来求解。 1. 等式优化问题 \[ \begin{align} \max\limits_x &amp; \ f(x) \\ s.t &amp; \ g(x) = 0 \end{align} \] 写出对应的拉格朗日函数为： \[ L(x, u) = f(x) + ug(x) \] 该问题转化为 ： \[ \max_{x, u} f(x) + ug(x) \] 在求解极值点的时候，我们采用求导的方法 \[ \left\{ \begin{align} f&#39;(x^*) + ug&#39;(x*) &amp;= 0 \\ g(x^*) &amp;= 0 \end{align} \right. \] 第一个等式是对 \(x\) 进行求导， 第二个等式是对 \(u\) 求导。所以通过该方法求解得到的解，一定是满足原问题的约束条件的，并且其最优解是原问题的最优解。 2. 只带有不等式约束的优化问题 \[ \min_x \ f(x) \\ s.t \left\{ \begin{align} g_1(x) \leq 0 \\ g_2(x) \leq 0 \\ g_3(x) \leq 0 \end{align} \right. \] - 拉格朗日函数 \[ L(x, u) = f(x) + u_1 g_1(x) + u_2g_2(x) + u_3g_3(x) \] 通过拉个朗日函数求得的解需要满足 KKT 条件才是满足原问题的最优解。 对应的 KKT 条件是： \[ \left\{ \begin{align} u_1^*, u_2^*, u_3^* \geq 0 \\ f&#39;(x^*) + u_1^*g_1&#39;(x*) + u_2^*g_2&#39;(x*) + u_3^* g_3&#39;(x^*) = 0 \\ u_1^*g_1(x^*) + u_2^*g(x^*) + u_3^*g(x^*) = 0 \end{align} \right. \] 对KKT条件的解释。 第二个条件，是为了求拉格朗日函数的极值而设定的。 第三个条件，使得最小的拉格朗日极值点也是 \(f(x)\) 的最小值。【互补松紧条件】。 第一个条件，因为加了第一个条件使得可以得到， 3. 既有等式约束又有不等式约束的问题 \[ \min\limits_x f(x) \\ s.t\left\{ \begin{align} h_i (x) = 0 \\ g_i (x) \leq 0 \end{align} \right. \] 广义拉格朗日函数 \[ L(x, \lambda, u) = f(x) + \lambda ^T h(x) + u^T g(x) \] 对应的 KKT 条件是 \[ \left\{ \begin{align} f&#39;(x^*) + \lambda^T h&#39;(x^*) + u^T g&#39;(x^*) &amp;= 0 \\ h_i(x^*) &amp;= 0 : 原问题自带的约束。 \\ g_i(x^*) &amp;\leq 0: 原问题自带的约束。 \\ u_i^* &amp;\geq 0 \\ u_i^*g_i(x*) &amp;=0 \end{align} \right. \]]]></content>
      <categories>
        <category>ML</category>
      </categories>
      <tags>
        <tag>KKT条件</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[$k$ 近邻法]]></title>
    <url>%2F2018%2F12%2F01%2Fstatistic_learning_method%2Fslm_chapter3%2F</url>
    <content type="text"><![CDATA[1 \(k\) 近邻法 \(k\) 近邻法的三个基本要素： \(k\)值的选择， 距离度量， 分类决策规则 ## 1.1 \(k\) 近邻算法 输入： 训练数据集 \[ T = \{ (x_1, y_1), (x_2, y_2),..., (x_N, y_N)\} \] 其中， \(x_i \in \mathcal{X} \subseteq R^n\)为实例的特征向量， \(y_i \in \mathcal{Y} ＝\{c_1， c_2,…,c_K\}\) 为实例的类别， \(i＝1,2,…,N\)； 实例特征向量\(x\)； 输出： 实例\(x\)所属的类\(y\). 根据给定的距离度量， 在训练集\(T\)中找出与\(x\)最邻近的\(k\)个点， 涵盖这\(k\)个点的\(x\)的邻域记作\(N_k(x)\)； 在\(N_k(x)\)中根据分类决策规则（如多数表决） 决定\(x\)的类别\(y\)： \[ y = \arg \max\limits_{c_j} \sum\limits_{x_i \in N_k (x)} I(y_i = c_j), i= 1,2,..,N; j=1,2,...,K \] 式中\(I\)为指示函数，即当\(y_i = c_j\)时\(I\)为1， 否则为0。 最近邻算法：取 \(k=1\) 时 1.2 距离度量 \(L_p\) 距离 \[ L_p (x_i, x_j) = \left( \sum\limits_{l=1}^n | x_i^{(l)} -x_j^{(l)} |^p \right)^{\frac{1}{p}} \] 这里的\(p\geq 1\),当\(p​\)取不同的值的时候会得到不同的距离。 当 \(p=2\)时， 称为欧式距离（Euclidean distance） 当 \(p=1\)时， 称为曼哈顿距离（Manhattan distance） 当 \(p=\infty\)时， 取各个坐标距离的最大值，即 \(L_{\infty} (x_i, x_j) = \max\limits_l |x_i^{(l)}-x_j^{(l)}|\) 1.3 \(k\) 值的选择 在应用中，$ k\(值一般取一个比较小的数值。 通常采用交叉验证法来选取最优的\)k$值. 1.4 分类决策规则 \(k\) 近邻法的决策规则实际上是多数表决，如果分类函数的损失函数是0-1损失函数，将损失函数表示为： \[f: R^n \rightarrow \{ c_1, c_2, ..., c_K \}\] 那么误分类的函数概率就是： \[P(Y \neq f(X)) = 1-P(Y=f(X))\] 对给定的实例 \(x \in X\), 其最近邻的\(k\) 个训练实例点构成集合\(N_k (x)\) 。如果涵盖\(N_k(x)\) 的类别是\(c_j\), 那么误分类率是: \[\frac{1}{k} \sum\limits_{x_i \in N_k(x)} I(y_i \neq c_j)= 1- \frac{1}{k} \sum\limits_{x_i \in N_k(x)}I(y_i =c_j)\] 多数表决规则等价于经验风险最小化。 1.5 \(k\)近邻法的实现： kd树 1.5.1 构造平衡kd树 输入: \(k\) 维空间数据集 \(T = \{ x_1, x_2, ..., x_N \}\), 其中\(x_i = (x_i^{(1)}, x_i^{(2)}, x_i^{(3)}, ..., x_i^{(k)})^T\), \(i = 1, 2, ..., N\) 输出： kd树 开始： 构造根结点， 根结点对应于包含\(T\)的\(k\)维空间的超矩形区域。 选择\(x^{(1)}\)为坐标轴， 以\(T\)中所有实例的\(x^{(1)}\)坐标的中位数为切分点， 将根结点对应的超矩形区域切分为两个子区域。 切分由通过切分点并与坐标轴\(x^{(1)}\)垂直的超平面实现。 由根结点生成深度为1的左、右子结点： 左子结点对应坐标\(x^{(1)}\)小于切分点的子区域， 右子结点对应于坐标\(x^{(1)}\)大于切分点的子区域。 将落在切分超平面上的实例点保存在根结点。 重复： 对深度为\(j\)的结点， 选择\(x^{(l)}\)为切分的坐标轴， \(l＝j( \text{mod} k)+1\)， 以该结点的区域中所有实例的\(x^{(l)}\)坐标的中位数为切分点， 将该结点对应的超矩形区域切分为两个子区域。 切分由通过切分点并与坐标轴\(x^{(l)}\)垂直的超平面实现。 由该结点生成深度为\(j+1\)的左、 右子结点： 左子结点对应坐标\(x^{(l)}\)小于切分点的子区 域， 右子结点对应坐标\(x^{(l)}\)大于切分点的子区域。 直到两个子区域没有实例存在时停止。 从而形成kd树的区域划分。 1.5.2 搜索kd树 输入： 已构造的kd树； 目标点\(x\)； 输出： \(x\)的最近邻。 在kd树中找出包含目标点\(x\)的叶结点： 从根结点出发， 递归地向下访问kd树。 若目标点\(x\)当前维的坐标小于切分点的坐标， 则移动到左子结点， 否则移动到右子结点。 直到子结点为叶结点为止。 以此叶结点为“当前最近点”。 递归地向上回退， 在每个结点进行以下操作： 如果该结点保存的实例点比当前最近点距离目标点更近， 则以该实例点为“当前最近点”。 当前最近点一定存在于该结点一个子结点对应的区域。 检查该子结点的父结点的另一子结点对应的区域是否有更近的点。 具体地， 检查另一子结点对应的区域是否与以目标点为球心、 以目标点与“当前最近点”间的距离为半径的超球体相交。 如果相交， 可能在另一个子结点对应的区域内存在距目标点更近的点， 移动到另一个子结点。 接着， 递归地进行最近邻搜索 如果不相交， 向上回退。 当回退到根结点时， 搜索结束。 最后的“当前最近点”即为\(x\)的最近邻点。 如果实例点是随机分布的， kd树搜索的平均计算复杂度是\(O(\log N)\)， 这里\(N\)是训练实例数。 kd树更适用于训练实例数远大于空间维数时的\(k\)近邻搜索。 当空间维数接近训练实例数时， 它的效率会迅速下降， 几乎接近线性扫描]]></content>
      <categories>
        <category>ML</category>
        <category>统计学习方法</category>
      </categories>
      <tags>
        <tag>$k$近邻法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[朴素贝叶斯法]]></title>
    <url>%2F2018%2F11%2F30%2Fstatistic_learning_method%2Fslm_chapter4%2F</url>
    <content type="text"><![CDATA[朴素贝叶斯法 1 极大似然估计， 最大后验， 贝叶斯估计。 极大似然估计 根据实验数据构造似然函数: \(f(\theta)\). 求取得最大值的参数\(\theta\). \(\arg\limits_{\theta} \max f(\theta)\) 最大后验估计 求最大后验 \(P(\theta |x_0) = \frac{P(x_0 | \theta)\times P(\theta)}{P(x_0)}\). 其中 \(P(\theta)\)是先验分布， \(P(x_0 | \theta)\)是似然函数。 因为\(P(x_0)\) 由实验结果决定，所以上述等价于最大化 \(P(x_0| \theta) \times P(\theta)\) 所以这个和极大似然估计相比，多了一项先验分布。 也是用来求 \(\arg\limits_{\theta} \max P(x_0| \theta) \times P(\theta)\) 贝叶斯估计 求后验分布 \(P(\theta | X) = \frac{P(X| \theta) \times P(\theta)}{P(X)}\), 通过实验可以确定 \(P(X)\), \(P(X|\theta)\) 是似然函数， \(P(\theta)\) 是先验分布。 在极大似然估计和 最大后验估计中都是通过做得的最为频繁发生的数据结果来推出当\(\theta\)满足某个值的时候能够最大可能性的得到这个结果。 贝叶斯估计是认为 \(\theta\)也是一个分布， 为了求解这个分布往往需要我们将先验分布和后验分布假设为共轭先验。 2 朴素贝叶斯法的学习和分类 2.1 朴素贝叶斯法基本概念 符号说明： \(x_i^{(j)}\) 是第\(i\)个样本的第\(j\)个特征； \(a_{jl}\) 是第\(j\)个特征可能取的第\(l\)个值； \(I\)是指示函数， 满足条件为1，否则为0. 我们首先看一张关于不同的名称之间关系的图(来源)： 根据这张图我们可以知道贝叶斯法和最大后验估计（maximum a posteriori estimation）是一样的。 只是采用了最大后验的方法来进行分类。 贝叶斯公式：我们首先列出在给定一个实例 \(X\) 的情况下对标签 \(Y\) 进行预测的公式（贝叶斯公式）： \[ P(Y= c_k| X=x) = \frac{P(X=x | Y=c_k)P(Y=c_k)}{\sum\limits_k P(X=x|Y=c_k)P(Y=c_k)}\] 预测未知数据就要求解的参数：我们需要通过已有的实验数据对未知的数据进行预测， 那么我们需要通过已有的数据得到先验概率分布 \(P(Y=c_k), k=1,2,...,K\) 和条件概率分布 \(P(X=x|Y=c_k) = P(X^{(1)}=x^{(1)}, ..., X^{(n)}=x^{(n)}|Y=c_k), k=1,2,...,K\) 。 最大似然求解先验概率分布：先验概率分布 \(P(Y=c_k), k=1,2...,K\)是容易通过已有数据得到的, 利用极大似然估计就能够得到： $P(Y=c_k) = , l=1,2,..,K $. 将 \(P(Y=c_k)\) 看做是参数， 似然函数是 \(P(Y=c_k) * N\). 参数过多：条件概率分布 \(P(X=x|Y=c_k) = P(X^{(1)}=x^{(1)}, ..., X^{(n)}=x^{(n)}|Y=c_k), k=1,2,...,K\) 是非常难求的。 因为对应于每个\(x^{j}\) 的可能取值有 \(S_j\) 个， 那么参数的个数有 \(K\prod\limits_{j=1}^nS_j\) 个。这里的参数指的就是 每一个条件概率 \(P(X=x|Y=c_k)\)。 比如\(n=10, S_j =10, K=10\) ,那么参数量是\(10^{11}\) ,显然就太多了。 条件独立性假设：为了解决条件概率参数太多的问题，贝叶斯法对条件概率做了条件独立的假设： \[ P(X=x|Y=c_k) = P(X^{(1)}=x^{(1)}, ..., X^{(n)}=x^{(n)}|Y=c_k)= \prod\limits_{j=1}^nP(X^{(j)}=x^{(j)}|Y=c_k)\] 引入了条件独立性假设的后验概率计算： \[\begin{align} P(Y= c_k| X=x) &amp;= \frac{P(X=x | Y=c_k)P(Y=c_k)}{\sum\limits_k P(X=x|Y=c_k)P(Y=c_k)} \\ &amp;= \frac{P(Y=c_k) \prod\limits_{j=1}^nP(X^{(j)}=x^{(j)}|Y=c_k) }{\sum\limits_k P(Y=c_k)\prod\limits_{j=1}^nP(X^{(j)}=x^{(j)}|Y=c_k) }\end{align} \] 贝叶斯分类器： \[y=f(x) = \arg\max\limits_{c_k} \frac{P(Y=c_k) \prod\limits_{j=1}^nP(X^{(j)}=x^{(j)}|Y=c_k) }{\sum\limits_k P(Y=c_k)\prod\limits_{j=1}^nP(X^{(j)}=x^{(j)}|Y=c_k) }\] 简化： 因为对于不同的 \(c_k\) 在已经学习好的模型（先验概率通过最大似然求出来了，条件概率通过条件独立性假设求出来了）上是一个常数，所以可以忽略掉分母： \[y=f(x) = \arg\max\limits_{c_k} P(Y=c_k) \prod\limits_{j=1}^nP(X^{(j)}=x^{(j)}|Y=c_k) \] 2.2 后验概率最大化的含义 朴素贝叶斯法将实例分到后验概率最大的类中， 这等价于期望风险最小化 证明： 损失函数为0-1损失函数。 \[ \begin{align} L(Y,f(X)) = \begin{cases} 1, Y\neq f(X) \\ 0, Y=f(X) \end{cases} \end{align} \] 期望风险函数等于 \(R_{exp}(f) = E[L(Y,f(X))]\) 在这里取联合期望为： \(R_{exp} (f) =E_{X} \sum\limits_{k=1}^K [L(c_k, f(X))]P(c_k | X)\) 为了使得期望风险最小， 只需要对\(X=x\) 逐个极小化，由此得到： \[ \begin{align} f(x) &amp;= \arg \min\limits_{y \in \mathcal{Y}} \sum\limits_{k=1}^K L(c_k , y) P(c_k|X=x) \\ &amp;= \arg \min_\limits{y \in \mathcal{Y}} \sum\limits_{k=1}^K P(y \neq c_k |X=x) \\ &amp;= \arg \min_\limits{y \in \mathcal{Y}} (1-P(y=c_k|X=c_k)) \\ &amp;= \arg \max_\limits{y \in \mathcal{Y}} P(y=c_k |X=x) \end{align} \] 所以，根据期望风险最小化准则就得到了后验概率最大化准则。 \[ f(x)= \arg \max_\limits{y \in \mathcal{Y}} P(y=c_k |X=x) \] 2.3 极大似然估计求解参数值 先验概率 \[ P(Y=c_k) = \frac{\sum\limits_{i=1}^N I(y_i = c_k)}{N}, k=1,2,...,K \] 条件概率 \[ \begin{align} P(X^{(j)}=a_{jl} | Y=c_k) = \frac{\sum\limits_{i=1}^{N}I(x_i^{(j)},y_i = c_k)}{\sum\limits_{i=1}^NI(y_i = c_k)} \\ j=1,2,...,n; l=1,2,...,S_j; k=1,2,...,K \end{align} \] 3 朴素贝叶斯算法（naive Bayes algorithm） 利用极大似然估计计算先验概率 \(P(Y=c_k)\) 和条件概率 \(P(X^{(j)}=a_{jl}|Y=c_k)\) 。 计算 \[ P(Y=c_k) \prod\limits_{j=1}^nP(X^{(j)}=x^{(j)}|Y=c_k) \] 确定类别 \[ y = \arg\max\limits_{c_k} P(Y=c_k) \prod\limits_{j=1}^nP(X^{(j)}=x^{(j)}|Y=c_k) \] 4 利用贝叶斯估计取代最大似然估计 用极大似然估计可能会出现所要估计的概率值为0的情况。 这时会影响到后验概率的计算结果， 使分类产生偏差。解决这一问题的方法是采用贝叶斯估计。 具体地， 条件概率的贝叶斯估计是： \[ P_\lambda(X^{(j)}=a_{jl} | Y=c_k) = \frac{\sum\limits_{i=1}^{N}I(x_i^{(j)},y_i = c_k) + \lambda}{\sum\limits_{i=1}^NI(y_i = c_k) + S_j\lambda} \] \(\lambda&gt;0\) , 当 \(\lambda=0\)的时候就是极大似然估计。 常取 \(\lambda=1\) 称为拉普拉斯平滑。 显然对于任意依噶条件概率都大于0 并且求和为1. 先验概率的贝叶斯估计是： \[ P_\lambda (Y=c_k) =\frac{\sum\limits_{i=1}^N I (y_i = c_k)+\lambda}{N+K\lambda} \] 5 贝叶斯估计， 最大后验， 最大似然， 朴素贝叶斯法 所有的这些方法都是建立在贝叶斯公式的基础上的。 最大后验，最大似然和贝叶斯估计都是对参数进行估计。 - 最大似然:它假设随机变量 \(X\) 满足某个分布，其中具有参数\(\theta\) , 根据 \(\theta\)我们可以写出得到某一组实验数据的概率表达式（似然函数）， 通过实验我们得到了一组实验数据\(x_0\), 我们通过对似然函数进行取对数然后求导的方法得到一个确定的\(\theta\)值，使得得到这组实验数据的概率最大。 最大后验：最大后验估计在最大似然的基础上引入了先验概率。 通过贝叶斯估计， 也能够得到不同的\(\theta\) 值得到\(X\) 的概率。 我们希望计算 \(\theta\)使得实验得到的\(x_0\) 在该后验概率中发生的可能性是最高的。 贝叶斯估计： 最大似然和最大后验，只是希望得到使得实验数据可能性最高的一个参数值，而贝叶斯估计中希望确定参数\(\theta\) 的分布， 为了能够确定这个分布， 我们需要使得贝叶斯公式得到的结果满足概率的几个要素（积分为1， 单调）。 因此常用共轭先验的方法来简化模型。 朴素贝叶斯法：朴素贝叶斯法是建立在贝叶斯定理和条件独立性假设下的分类算法。 在利用朴素贝叶斯法建立分类模型时，相关的先验分布， 条件分布的参数一般是通过最大似然的方法和贝叶斯估计的方法求得的。 贝叶斯法是一种生成模型]]></content>
      <categories>
        <category>ML</category>
        <category>统计学习方法</category>
      </categories>
      <tags>
        <tag>朴素贝叶斯</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[感知器学习算法]]></title>
    <url>%2F2018%2F11%2F29%2Fstatistic_learning_method%2Fslm_chapter2%2F</url>
    <content type="text"><![CDATA[1 感知机 1.1 感知机模型 定义： \[ \begin{align} f(x) &amp;= \text{sign} (wx+b) \\ \text{sign}(x) &amp;= \begin{cases} +1, x \leq 0 \\ -1, x&lt;0 \end{cases} \end{align} \] 属性： 线性分类模型， 判别模型 假设空间： 所有线性分类模型 损失函数（经验风险损失）： \[L(w,b) = -\sum\limits_{x_i \in M} y_i (wx_i +b)\] 其中 \(M\) 是误分类点的集合。 因为对于 \((wx_i +b) &gt;0\) 的情况其预测标签为1， 对于误分类的情况实际标签为\(-1\)。 因此，需要使得 \((wx_i +b)​\) 往0处靠近。 所以可以采用这个作为损失函数。 1.2 感知器学习算法 方法： 随机梯度下降算法(stochastic gradient descent) 梯度： \[ \begin{align} \Delta_w L(w,b) &amp;= -\sum_{x_i \in M} y_i x_i \\ \Delta_b L(w,b) &amp;= -\sum_{x_i \in M} y_i \end{align} \] 梯度的更新 随机的选择一个误分点进行更新： \[ \begin{align} w &amp;= w+\eta y_i x_i \\ b &amp;= b+\eta y_i \end{align} \] \(0&lt;\eta\leq1\) 在统计学习中又称为学习率. 例子1 如图2.2所示的训练数据集， 其正实例点是\(x_1＝(3,3)^T， x_2＝(4,3)^T​\)， 负实例点是\(x_3＝(1,1)^T​\)， 试用感知机学习算法的原始形式求感知机模型\(f(x)＝\text{sign}(w·x+b)​\)。 这里， \(w＝(w^{(1)},w^{(2)})T， x＝(x^{(1)},x^{(2)})\) 代码： 1234567891011121314151617import numpy as npx = np.matrix([[3, 3], [4, 3], [1, 1]])y = [1, 1, -1]w = np.matrix([[0], [0]])b = 0lr = 1flag = 0while flag&lt;3: flag = 0 for i in range(len(data)): tmp = (data[i]*w + b) * y[i] if (tmp[0, 0] &lt;= 0): # 被误分 w = w + lr*y[i]*x[i].T b = b + lr*y[i] print(w.T, b) else: flag += 1 结果： 12345678[[3 3]][[3 3]] 1[[2 2]] 0[[1 1]] -1[[0 0]] -2[[3 3]] -1[[2 2]] -2[[1 1]] -3 1.3 算法的收敛性 1.4 感知器学习算法的对偶形式 1.4.1 说明： 感知器采用随机梯度下降的方法进行梯度下降的迭代过程如下： \[ \begin{align} w &amp;= w + \eta y_i x_i \\ b &amp;= b + \eta y_i \end{align} \] 在经过\(n\) 次的迭代之后，\(w\) 和 \(b\) 受到第\(i\)个样本\((x_i ,y_i)\)的影响所改变值分别是 $n_i y_i x_i $ 和 \(n_i \eta y_i\)。\(n_i\)表示第 \(i\)个样本出现错判的次数。 \(\eta\) 是学习率。 用\(\alpha_i\) 表示\(n_i \eta\) 因此，不难得到最后的\(w\) 和 \(b\) 分别是： \[ \begin{align} w &amp;= \sum\limits_{i=1}^N \alpha_i y_ix_i \\ b &amp;= \sum\limits_{i=1}^N \alpha_i y_i \end{align} \] \(n_i\) 又称为第\(i\)个实例点更新的次数，实例点更新次数越多说明该点越接近超平面，也就越难正确分类。 1.4.2 算法 输入: 训练数据集\(T = \{(x_1， y_1),(x_2,y_2),...,(x_N,y_N)\}\)， 其中$x_i=R_n, y_i={-1,+1}, \[ i=1,2,...,N$; 学习率 $\eta$ $(0&lt;\eta \leq1)$。 **输出**: $\alpha,b$；感知机模型$f(x)＝\text{sign}\left( \sum\limits_{j=1}^N \alpha_j y_j x_j \cdot x+b \right)$。 其中 $\alpha = (\alpha_1, \alpha_2, ..., \alpha_N)^T$ (1) $\alpha = 0, b = 0$ (2) 在训练集中选取数据$(x_i, y_i)$ (3) 如果 $y_i \left( \sum\limits_{j=1}^N \alpha_j y_j x_j \cdot x+b \right) \leq 0$: \] \[\begin{align} \alpha_i &amp;= \alpha_i +\eta\\ b &amp;= b + \eta y_i \end{align}\] \[ (4) 转至（2）直到没有误分类数据。 对偶形式中训练实例仅以内积的形式出现。 为了方便， 可以预先将训练集中实例间的内积计算出来并以矩阵的形式存储， 这个矩阵就是所谓的Gram矩阵（Gram matrix） \] G = [x_i x_j]_{N N} $$ 1.4.3 例子 数据同例1， 正样本点是\(x_1＝(3,3)^T， x_2＝(4,3)^T\)， 负样本点是\(x_3＝(1,1)^T\)， 试用感知机学习算法对偶形式求感知机模型. - 代码 123456789101112131415161718192021222324252627282930import numpy as np# 变量初始化x = np.matrix([[3, 3], [4, 3], [1, 1]])y = np.matrix([[1], [1], [-1]])alpha = np.matrix([0, 0, 0])b = 0lr = 1# 计算Gamma 矩阵G = np.matmul(x, x.T)# 迭代更新 alpha 和 bnum = 0while num&lt;3: num = 0 for i in range(len(x)): tmp = np.sum(np.multiply(np.multiply(alpha, y.T), G[i] )) tmp += b tmp *= y[i, 0] if tmp &lt;= 0: alpha[0, i] += lr b += y[i]*lr print(alpha, b) else: num += 1 w = np.multiply(np.multiply(alpha.T, y), x)w = np.sum(w, 0)print("w:", w, " b:", b) 结果 12345678[[1 0 0]] [[1]][[1 0 1]] [[0]][[1 0 2]] [[-1]][[1 0 3]] [[-2]][[2 0 3]] [[-1]][[2 0 4]] [[-2]][[2 0 5]] [[-3]]w: [[1 1]] b: [[-3]]]]></content>
      <categories>
        <category>ML</category>
        <category>统计学习方法</category>
      </categories>
      <tags>
        <tag>感知器</tag>
        <tag>线性分类， 对偶问题</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[统计学习方法概论]]></title>
    <url>%2F2018%2F11%2F27%2Fstatistic_learning_method%2Fslm_chapter1%2F</url>
    <content type="text"><![CDATA[1 统计学习 1.1 统计学习的特点 平台是计算机和网络 研究对象是数据 目的是对数据进行预测和分析 以方法为中心 （构建模型） 是概率论，统计学，信息论， 计算理论等多个领域的交叉学科 1.2 统计学习方法的三个要素 模型的假设空间（模型） 模型选择的准则（策略） 模型学习的算法（算法） 1.3 分类 监督学习 非监督学习 半监督学习 强化学习 2 监督学习 2.1 基本概念 符号集合 符号 含义 \(X\) 输入变量， 文中的所有变量都是列向量 \(Y\) 输出变量， 文中的所有变量都是列向量 \(x\) 输入变量的取值 \(x=(x^{(1)}, x^{(2)},...,x^{(i)},...,x^{(n)})^T\) \(x_i\) 第\(i\)个变量的取值 \(x_i = (x_i^{(1)}, x_i^{(2)},...,x_i^{(i)},...,x_i^{(n)})^T\) \(T\) 训练数据的集合 \(T=\{(x_1,y_1), (x_2,y_2), ..., (x_N, y_N)\}\) \(\mathcal{X}\) 由输入变量 \(X\) 组成的输入空间 \(\mathcal{Y}\) 由输出变量 \(Y\) 组成的输入空间 \(\mathcal{F}\) 假设空间（模型空间，自己取得名字） \(L(Y, f(X))\) 由模型的预测\(f(x)\) 和 实际标签\(Y\) 组成的损失函数 输入空间和输出空间 将输入和输出所有可能取值的集合称为输入空间。 ### 特征向量（feature vector） 每个具体的输入是一个实例（instance），通常由特征向量表示。 ### 特征空间（feature space） 所有的特征向量存在的空间称为特征空间。 ### 回归问题和分类问题 - 回归问题： 输入变量和输出变量均为连续变量的预测问题。 - 分类问题： 输出变量为有限个离散变量的预测问题为分类问题。 ### 联合概率分布和假设空间 - 监督学习的基本假设： 假设数据之间存在一定的统计规律， \(X\) 和 \(Y\)之间存在着联合概率分布。 并且认为训练数据和测试数据是依联合概率分布 \(P(X,Y)\) 独立同分布产生的。 - 假设空间（hypothsis space）： 输入输出之间映射的集合（所有可能的模型）。 由条件概率 \(P(Y|X)\) 或者决策函数（decision function) \(Y=f(x)\) 表示。 3 统计学习中的三要素 统计学习方法由三部分组成可以简单的表示： 方法 = 模型+策略+算法 3.1 模型 在监督学习过程中模型就是所学的条件概率分布或者决策函数。 模型的假设空间\(\mathcal{F}\)由所有可能的条件概率分布或者决策函数组成。 因此假设空间\(\mathcal{F}\)可以通过下面这些式子表示。 决策函数的集合 普通的写法 \[ \mathcal{F} = \{ f| Y = f(X) \} \] 由于假设空间通常是由一个参数向量决定的函数族，所以也可以写成 \[ \mathcal{F} = \{ f| Y = f_\theta (X) \} \] 条件概率的集合 一般的写法 \[ \mathcal{F} = \{ P| P(Y|X) \} \] 加上参数的写法 \[ \mathcal{F} = \{ P| P_\theta (Y|X) \} \] 3.2 策略 tags: 损失函数， 风险函数， 期望风险， 期望损失， 经验风险， 经验损失， 结构风险 ### 3.2.1 极大似然估计 + 最大后验概率估计 - 极大似然估计（maximum likelihood estimation 简称MLE） 通过实验得到实验结果 \(x_0\)， 通过先验知识确定这个实验结果出现的概率函数称为似然函数 \(P(x_0|\theta)\), 最后通过取对数值然后求导等方法求得使似然函数取最大值事的参数 \(\theta\)。 - 最大后验概率估计(maximum a posterior probability estimation 简称MAP) 通过实验数据找到最合适的参数 \(P(\theta|x_0)\), 由于 \(P(\theta|x_0) = \frac{P(x_0|\theta) \times P(\theta)}{P(x_0)}\)， 因为 \(P(x_0)\) 可以通过实验得到，因此最大化后验只需要求最大化 \(P(x_0|\theta) \times P(\theta)\) 前半部分是似然函数， 后半部分是先验。 3.2.2 相关概念 损失函数（loss function）： 又称代价函数(cost function) 用来度量预测错误的程度。 损失函数是 \(f(X)\) 与 \(Y\) 的非负实值函数。 记为 \(L(Y, f(X))\)。 常见的损失函数 0-1 损失函数 (0-1 loss function) \[ L(Y,f(X)) = \begin{array}{lc} 1&amp;, Y\neq f(X) \\ 2&amp;,Y=f(X) \end{array} \] 平方损失函数（quadratic loss function） \[ L(Y,f(X)) = (Y-f(X))^2 \] 绝对值损失函数（absolute loss function） \[L(Y,f(X)) = |Y-f(X)| \] 对数损失函数（logarithmic loss function） 或者 对数似然损失函数 (likelihood loss function) \[ L(Y,P(Y|X)) = -\log (P(Y|X)) \] 风险函数（risk function） 又称 期望损失（expected loss） \[ R_{exp} (f) = E_p [L(Y, f(X))] = \int_{\mathcal{X} \times \mathcal{Y}} L(x, f(x)) P(x, y) dxdy\] 经验风险 （empirical risk） 又称 经验损失 （empirical loss） \[ R_{emp} (f) = \frac{1}{N} \sum\limits_i^N L(y_i, f(x_i)) \] 经验风险最小化与结构风险最小化 经验风险最小化 \[\min\limits_{f \in \mathcal{F}} \frac{1}{N} \sum\limits_{i=1}^N L(y_i, f(x_i))\] 当模型是条件概率分布，损失函数是对数损失函数，经验风险最小化就等价于最大似然估计。 结构风险最小化 结构风险最小化(structural risk minimization, SRM)： $R_{srm} (f) = _{i=1}^N L(y_i, f(x_i)) +J(f) $ \(J(f)\) 是定义在假设空间 \(\mathcal{F}\) 上的泛函，模型越复杂越大。\(\min R_{srm}(f)\) 当模型是条件概率分布，损失函数是对数损失函数, 模型的复杂度由模型的先验概率表示时，结构风险最小化就等价于最大后验概率估计。 3.3 算法 算法： 学习模型的具体计算方法。 统计机器学习基于训练数据集，根据学习策略（模型） ，从假设空间中通过相应的算法求解最优模型。 统计学习问题可以归结为最优化问题。 4. 模型的评估和模型的选择 注：1.统计学习方法具体采用的损失函数未必是评估时使用的损失函数。 2. 通常将学习方法对未知数据的预测能力称为泛化能力（generalization ability） - 过拟合： 参数过多， 已知数据预测很好， 未知数据预测很差 - 奥卡姆剃刀（Occam's razor） 原理：能解释已知数据，并且十分简单才是最好的模型。 ## 4.1 模型选择的方法 - 正则化：${f} {i=1}^N L(y_i, f(x_i)) +J(f) $ 也就是结构风险最小化。 常用的正则化项包括对参数向量的一范式和二范式。 - 交叉验证：数据不充分的时候切分数据集反复进行训练，测试和模型选择。 - 简单交叉验证 - S折交叉验证 - 留一交叉验证 4.2 泛化误差, 泛化误差上界（29页） 证明(......) 训练误差小的模型， 其泛化误差也会小 5 生成模型和判别模型 5.1 生成模型 由数据学习联合概率分布 \(P(X, Y)\), 求出条件概率分布 \(P(Y|X)\) 作为预测的模型，即生成模型。 $P(Y|X) = $ 常用的方法： 朴素贝叶斯方法和隐马尔科夫模型 特点： 1. 能够还原出联合概率分布\(P(X, Y)\)； 2.学习收敛速度快； 3. 当存在隐变量的时候任然能够用生成模型学习。 5.2 判别模型 由数据直接学习决策函数 \(f(x)\) 或者条件概率分布 \(P(Y|X)\) 作为预测的模型。 判别模型关系的是给定的 \(X\) 应该预测什么样的输出 \(Y\)。 常用的方法：k 近邻法， 感知器， 决策树， 逻辑斯迪克回归， 最大熵模型， 支持向量机， 提升方法和条件随机场等。 特点： 1. 直接学习条件概率\(P(Y|X)\)或者决策函数\(f(X)\) ,直接面对预测，往往学习率更高； 2. 可以对数据进行各种程度上的抽象，定义特征并使用特征，因此可以简化学习问题。 6 分类问题 评价指标 精确率： \(P = \frac{TP}{TP+FP}\) 召回率： \(R = \frac{TP}{TP+FN}\) \(F_1\)值：\(\frac{2}{F_1} = \frac{1}{P} + \frac{1}{R}\) =&gt; \(F_1 = \frac{2TP}{2TP+FP+FN}\) 主要的分类方法： k近邻法、 感知机、 朴素贝叶斯法、 决策树、决策列表、 逻辑斯谛回归模型、 支持向量机、 提升方法、 贝叶斯网络、 神经网络、Winnow 等。 7 标注问题 训练数据： \(T = \{ (x_1, y_1), (x_2, y_2), ..., (x_N, y_N) \}\)。 其中 \(x_i = (x_i^{(1)}, x_i^{(2)},..., x_i^{(n)})^T\) 对应的标记序列是：\(y_i = (y_i^{(1)}, y_i^{(2)}, ..., y_i^{(n)})^T\)。 学习系统： 表示为条件概率为： \(P(Y^{(1)}, Y^{(2)}, ..., Y^{(n)}| X^{(1)}, X^{(2)}, ..., X^{(n)})\) 评价指标： 和分类问题一样，标注准确率， 精确率和召回率。 学习方法： 隐马尔可夫模型， 条件随机场 8 回归问题 回归模型表示从输入变量到输出变量之间映射的函数， 回归问题的学习等价于函数拟合。 - 模型： \(Y = f(X)\) - 损失函数： 平方损失函数（在此情况下可以采用最小二乘法求解）。 9 习题 9.1 说明伯努利模型的极大似然估计以及贝叶斯估计中的统计学习方法三要素。 伯努利模型是定义在取值为0与1的随机变量上的概率分布。 假设观测到伯努利模型n次独立的数据生成结果， 其中k次的结果为1， 这时可以用极大似然估计或贝叶斯估计来估计结果为1的概率。 统计学习方法三要素： 模型， 策略， 算法 极大似然估计： 介绍： 已经通过实验获取得到了实验结果 \(x_0\), 找到一组参数使得理论上生成实验结果 \(P(x_0 | \theta )\) 的概率是最大的. 结合伯努利模型： 在 \(n\) 次独立同分布的实验中，我们通过实验得到了一组实验数据 \(x_0\), 比如这个实验是在抛硬币,\(n=10\), 参数 \(\theta\) 表示在每次独立的实验中硬币正面朝上的概率为\(\theta\)。 我们可以通过这组实验知道： 实验中出现 \(k\) 次正面朝上的概率是 \(\theta^k (1-\theta)^{n-k}\) 我们希望找到的参数 \(\theta\) 能够使得这个概率最大。 因此我们可以对这个概率公式取对数然后求导得到当\(\theta = \frac{k}{n}\) 的时候取得最大值。 三要素： 模型：伯努利模型； 策略： 对数损失函数； 算法： 求经验风险最小值， 求导。 贝叶斯估计 还没总结完， 太多了！]]></content>
      <categories>
        <category>ML</category>
        <category>统计学习方法</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[贝叶斯公式+最大似然估计+最大后验概率公式+贝叶斯估计]]></title>
    <url>%2F2018%2F11%2F26%2Fstatistic_learning_method%2FBT_MLE_MAP%2F</url>
    <content type="text"><![CDATA[来源： https://blog.csdn.net/u011508640/article/details/7281598 # 贝叶斯公式+最大似然估计(MLE)+最大后验概率公式(MAP)+贝叶斯估计 ## 1.贝叶斯公式 \[ P(A|B) = \frac{ P(B|A) \times P(A) }{ P(B|A) \times P(A) + P(B|\sim A) \times P(\sim A) } \] - 作用： - 你有多大把握相信一件证据。 给定 \(B\) 的时候，你有多大的可能性会去相信 \(A\) 能够成立。 - 在做判断的时候需要考虑所有的因素。 - 一件很难发生的事情 \(P(A)\) 即使出现某个证据 \(B\) 和它强相关 \(P(B|A)\) 也要谨慎，因为证据可能来自其他虽然不是强相关但发生概率较高的事情 因为 \(P(B|\sim A) \times P(\sim A)\) 可能会比较大从而导致\(P(B|A)\) 比较小。 - 根据已知的或者主观容易断定的条件概率事件，计算出未知的或者较难评估的条件概率事件 2. 似然函数 对于函数 \(P(x| \theta)\): - 当 \(\theta\) 是已知的情况下， \(x\) 是变量， 这个函数叫做概率函数（probability function）, 用来描述对于不同的样本点 \(x\) , 其出现的概率是多少。 - 当 \(x\) 是已知的情况下， \(\theta\) 是变量， 这个函数叫做似然函数（likelihood function）, 用来描述对于不同的模型参数， 这个样本点出现的概率是多少。 3. 最大似然估计（maximum likelihood estimation : MLE） 最大似然估计的核心思想是认为当前发生的事件是概率最大的 构造一个关于参数 \(\theta\) 的函数， 这个函数用来表示在已知的一组实验中产生了一组实验数据 \(x_0\) 的可能性。 在抛硬币实验中，每次抛硬币出现正反的概率满足二项分布。 比如抛了10次，出现的一组实验数据 \(x_0=[0111101110]\)。 似然函数为： \(f(\theta) = ((1−\theta) × \theta × \theta × \theta × \theta × (1 − \theta)× \theta × \theta × \theta ×(1−\theta))=\theta^7 \times (1 - \theta)^3\) 计算使似然函数最大的参数值， 一般先取对数然后计算。 \(\log f(\theta) = 7\log \theta + 3\log (1-\theta)\) 求导可以得到： \(\frac{7-10\theta}{\theta (1-\theta)}\) 可以得到当\(\theta = 0.7\) 的时候能够得到最大值。 ## 4. 最大后验概率估计（maximum a posterior probability estimation: MAP） 最大似然估计的目的是通过求解得到 \(\theta\) 使得似然函数 \(P(x_0|\theta)\) 达到最大。 而最大后验概率估计是在最大似然估计的情况下考虑先验概率分布\(P(\theta)\) 。使得 \(P(\theta) \times P(x_0 | \theta)\) 达到最大。 最大后验概率估计的目的其实是为了最大化后验： $P(| x_0) = $ 因为 \(P(x_0)\) 是可以通过做实验得到的。 所以只需要求解 \(P(\theta) \times P(x_0 | \theta)\) 使其最大。 最大后验的名字来源于 \(P(\theta | x_0)\) 就是要在已有实验数据的情况下求解最合理的参数。 5. 贝叶斯估计 （感觉这部分理解的不是特别到位） 介绍： 不论是极大似然估计还是最大后验分布，我们都是通过构造一个似然函数（最大后验分布中还需要假设先验分布）， 来构建一个模型， 最后利用这个对数似然函数作为损失函数来求解相应的参数， 当参数固定的时候。模型也就确定了。 贝叶斯估计和最大后验相比目的不是为了得到一个最可靠的参数值，而是假设这个参数也服从某些分布。 因此我们需要通过一定的方法求解这个分布。 贝叶斯公式中\(P(\theta | X) = \frac{P(X | \theta) \times P(\theta)}{P(X)}\) 在最大后验估计和最大似然中有一个基本的假设是认为当前发生的事件概率最大， 通过带入具体的 \(X=x_0\) 来求解参数。因此可以不用考虑 分母， 因为当\(X=x0\) 的时候分母就是一个常数了。 但是现在我们希望求的是 \(P(\theta | X)\) 这个分布， 因此 \(P(X)\) 是不能够当成常数处理的， 这是一个分布。 \(P(X)\) 可以通过联合概率进行求解：\(\int_{\theta} P(X | \theta) d\theta\) . : 对于\(P(X)\) 要怎么求 我还不确定， 搞懂了再补吧! 注： \(P(X)\) 应该是通过实验作出来的， 当训练数据集确定了， 那么这个分布是能够确定下来的。 简便求解的方法： 将先验分布和后验分布构造成共轭先验。 那么可以将\(P(X)\) 看成一个常数。因为这样知道了后验分布通过积分为1容易求得均值方差。 6. 一个简单的例子 投硬币10次得到的结果是\(x_0 = [0111101110]\) - 最大似然函数， 上面已经说过了对应的似然函数是： \(f(\theta) =\theta^7 \times (1 - \theta)^3\) - 代码： 12345678910111213import mathimport matplotlib.pyplot as pltdef mle_value(): """最大似然估计： x表示 θ 值""" x = [0.001*i for i in range(0, 1000)] # 不同的参数 θ 的值 y = [i**7 * (1-i)**3 for i in x] # θ对应的似然函数值 print('对应最大值的θ是:', x[y.index(max(y))]) plt.plot(x, y) plt.xlabel('θ') plt.ylabel('likelihood function value') plt.show() 结果 根据先验知识假定 P(θ) 为均值为0.5， 方差为0.1 的高斯函数，可以画出对应的概率密度图&quot; 代码 12345678910111213def prior_value(): """根据先验知识假定 P(θ) 为均值为0.5， 方差为0.1 的高斯函数，所以可以画出 θ 和 P(θ) 的图像： 一个高斯分布的密度函数，密度越大可能性越大""" def p_theta(u): return 1/((2*math.pi*0.01)**(1/2))*math.exp(-(u-0.5)**2/(2*0.01)) x = [i*0.001 for i in range(0, 1000)] y = [p_theta(i) for i in x] print('对应最大概率密度的θ值是:', x[y.index(max(y))]) plt.plot(x, y) plt.xlabel('θ') plt.ylabel("p(θ)") plt.show() 结果 \(P(\theta)\) 的先验知识和似然函数\(P(x_0 | \theta)\) 可以画出后验的图 代码 123456789101112"""假定 p(θ) 满足均值为 0.5 方差为 0.1 的概率密度的情况下， 计算联合概率密度的值 p(xo|θ)*p(θ)， 联合概率反映了后验概率的数值大小 """ def p_theta(u): return (1/((2*math.pi*0.01)**(1/2))*math.exp(-(u-0.5)**2/(2*0.01))) * (u**7 *(1-u)**3) x = [i*0.001 for i in range(0, 1000)] y = [p_theta(i) for i in x] print('对应最大联合概率密度的θ值是:', x[y.index(max(y))]) plt.plot(x, y) plt.xlabel('θ') plt.ylabel("p(xo|θ)*p(θ)") plt.show() 结果 \(P(\theta)\) 的先验知识和似然函数\(P(x_0 | \theta)\) 通过多做几次实验可以得到更加准确的结果 代码 1234567891011121314def map_value100(): """ 实验了100次会得到的结果 """ def p_theta(u): return (1/((2*math.pi*0.01)**(1/2))* math.exp(-(u-0.5)**2/(2*0.01))) * (u**7 *(1-u)**3)**70*(u**7 *(1-u)**3)**30 x = [i*0.001 for i in range(0, 1000)] y = [p_theta(i) for i in x] print('对应最大联合概率密度的θ值是:', x[y.index(max(y))]) plt.plot(x, y) plt.xlabel('θ') plt.ylabel("p(xo|θ)*p(θ)") plt.show() 结果]]></content>
      <categories>
        <category>ML</category>
      </categories>
      <tags>
        <tag>贝叶斯公式， Bayes’ Theorem</tag>
        <tag>最大似然估计， 最大后验概率估计， MLE</tag>
        <tag>MAP</tag>
        <tag>maximum likelihood estimation</tag>
        <tag>maximum a posterior probability estimation</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在机器学习中数据不平衡问题的解决]]></title>
    <url>%2F2018%2F11%2F25%2F%E5%9C%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E6%95%B0%E6%8D%AE%E4%B8%8D%E5%B9%B3%E8%A1%A1%E9%97%AE%E9%A2%98%E7%9A%84%E8%A7%A3%E5%86%B3%2F</url>
    <content type="text"><![CDATA[在机器学习中数据不平衡问题的解决 出处： https://www.cnblogs.com/zhaokui/p/5101301.html ### 例子： 在所有的微博对应的评论数量划分为1到5这5个等级。 1少5多。 大部分的评论都很少，极少数的微博评论会非常的多。 如果我们要对一些微博的评论数量进行预测。 只要全部预测为1，就能够得到非常高的准确率， 显然这样的预测是没有意义的。 将问题分为4个类别 数据量 分布是否均匀 大 均匀 大 不均匀 小 均匀 小 不均匀 注： 当每个类别的数据量大于5000 个以上的时候，正负样本数量相差一个量级是能够接受的（经验之谈）。 主要的解决方法 采样 方法 做法 问题 解决方法 上采样 小样本复制多分 过拟合 加入随机扰动 下采样 剔除一部分大样本 信息损失 EasyEnsemble)：多次放回的独立采样构建多个独立的模型，然后将多个模型进行组合 BalanceCascade: 在EasyEnsemble的基础上前面训练得到的模型预测准确的样本不放回。NearMiss: 利用KNN挑选出最具代表性的大众样本 数据合成 SMOT 方法： 对于小众样本 \(x_i \in S_{min}\) 从它的 k 近邻中随机选取一个点\(\hat{x}\)。 生成新的小众样本 \(x_{new}=x_i + (\hat{x}-x_i) \times \delta\) , 其中 \(\delta \in [0,1]\) 是一个随机数。 存在的问题： 1. 增加了类之间重叠的可能性。 2. 生成了一些没有提供有益信息的样本。 下面两种方法用来解决这些问题。 Borderline-SMOTE 只对小众样本中那些 k 近邻中大部分是大众样本的点通过SMOTE生成新样本。 因为这些样本往往是边界样本 ADASYN 首先计算每个小众样本在需要使整个数据集达到平衡时需要增加的数据量记为 \(G\). 再计算对于具体的一个小众样本中每个点需要生成的样本占 \(G\) 的比例。 \[\mathcal{T}_i = \frac{\Delta_{ik}}{\sum_i \Delta_{ik}} \] 其中的\(\Delta_{ik}\) 是第\(i\) 个样本点中\(k\)近邻中大众样本的个数。 计算小众样本中每个点需要利用SMOT方法生成的点的个数： \(g_i = \mathcal{T}_i \times G\) 加权 对于不同的类别分成其他的类别时对应的损失是不同的。 将 \(c(i,j)\) 视为是把真实样本类别为 \(j\) 的时候分类成 \(i\) 时的损失。 该方法的难点在于如何确定 \(c(i,j)\). 一分类 当正负样本分布及其不均匀的时候，可以将这个模型看成是一分类或者异常检测的问题。 其中经典的工作包括 One-class SVM 。 方法的选择 正负样本均很少： 数据合成 正负样本比例悬殊：-分类 数据量还行，比例不是特别悬殊： 采样和加权的方法 采样和加权在数学上等价，但是实际中在计算资源合适的情况下，采样会好一点。 有空可以看看 Learning from Imbalanced Data 这篇综述。]]></content>
      <categories>
        <category>others</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>数据不平衡</tag>
        <tag>SMOT</tag>
        <tag>Border-line SMOT</tag>
        <tag>ADASYN</tag>
        <tag>采样， 加权， 一分类</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[这是一篇对 hexo 中对 markdown 中各种格式支持的实验]]></title>
    <url>%2F2018%2F11%2F25%2Fmarkdown_test%2F</url>
    <content type="text"><![CDATA[这是一篇对 hexo 中对各种格式支持的实验 添加图片 公式 插入公式 \(\frac{1}{2}=0.5\) , \[ \begin{align} y &amp;= \sigma (W[x,y]+b)\\ x &amp;= 0 \end{align} \] 插入表格 表头1 表头2 表头3 表头4 默认左对齐 左对齐 居中对其 右对齐 默认左对齐 左对齐 居中对其 右对齐 默认左对齐 左对齐 居中对其 右对齐 高亮：==哈哈哈哈== 删除线：哈哈哈 代码： 123456789101112import tensorflow as tfif __name__ == "__main__": sum = 0 for i in range(101, 200): flag = True for j in range(2，i//2+1: if i%j == 0: flag = False break if flag: sum += 1 print(sum) [^]: 这是一段脚注 这是一段引用 a b \(\mathcal{X}, \mathcal{Y}\) \[ L(Y,f(X)) = \left\{ \begin{align} 1&amp;, Y\neq f(X) \\ 2&amp;,Y=f(X) \end{align} \right\}​\]]]></content>
      <categories>
        <category>others</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[利用hexo 和 github 搭建自己的博客 （Windows）]]></title>
    <url>%2F2018%2F11%2F23%2F2018_11_23_hexo_blog%2F</url>
    <content type="text"><![CDATA[利用hexo 和 github 搭建自己的博客 （Windows） 安装Node.js 和 Node.js 环境 下载 Node.js 安装，可以直接选择添加环境变量 cmd 输入 node -v 会显示版本信息 安装 github win_git 下载很慢 打开cmd 输入 git --version 会显示 github 的版本信息 在github 中创建一个新的repository(仓库) 仓库名称的后缀名称必须是XX.github.io， 这里的名称应该是自己github 的名字（其他的不清楚会怎么样） Initialize this repository with a README 这个选项需要勾选 创建好之后， 找到sittings 按钮， 向下拉， 看到有个网站。如果没有的话需要将source 改为master branch. 主题也可以选一个，这个主题是readme对应的markdown 文件显示的主题。 然后点开， 你可以看到readme 中的一些内容了。 安装Hexo 创建一个文件夹 cd 到该目录下，将Hexo 安装在该目录下。 npm install hexo -g 安装 Hexo. （npm命令是安装node.js 的时候装上的。） hexo -v 可以确定安装成功与否 初始化该文件夹： hexo install （需要一点时间） 安装所需组件：npm install hexo g (我猜是编译吧) hexo s (启动服务器); 更具提示输入网址，可以进入初始页面。 如果进不去可能是端口被占用了通过如下方法修改端口号。 Ctrl +C 停止服务 hexo server -p 5000 (最后面那个是端口号) 将Hexo 和 github page 联系起来。 （下面这些步骤用git bash here 打开， git 安装好以后鼠标右键就有了） 如果是第一次的话，需要设置 git 的 user name 和 email (将本地的git 指定自己的账户) git config --global user.name &quot;XXXX&quot; , XXXX 是自己github 的用户名 git config --global user.email &quot;XXXX&quot;, XXXX是自己github的邮箱 利用ssh 和邮件生成秘钥和密匙。 cd ~/.ssh ssh-keygen -t rsa -C “XXXX@qq.com” 在C:.ssh 下面会得到两个文件， id_rsa和id_rsa.pub 添加密钥到ssh-agent: eval &quot;$(ssh-agent -s)&quot; 添加生成的SSH key到ssh-agent: ssh-add ~/.ssh/id_rsa 登录Github，点击头像下的settings，添加ssh 新建一个new ssh key，将id_rsa.pub文件里的内容复制到key中, Title 的内容可以随便填。 验证是否成功： ssh -T git@github.com 看到Hi 后面的内容表明成功了。 123Administrator@4H516J30FXZVCK3 MINGW64 /e/blog$ ssh -T git@github.comHi hekang123456! You've successfully authenticated, but GitHub does not provide shell access. 配置Hexo 和 git 之间建立连接 打开 _config.yml 修改最后的内容是 1234deploy: type: git repository: git@github.com:hekang123456/hekang123456.github.io.git branch: master repository 中的内容可以直接在 github 中对应的仓库中点下载， 选user SSH 复制下载中的连接地址 新建一篇博客 新建一篇博客，实际上是新建了一个markdown 在 “source/_posts/” 文件下面： hexo new post “hello word2！” 部署前安装一些扩展： npm install hexo-deployer-git --save 生成博客并且部署： hexo d -g 查看显示的博客内容： https:// XXXX.github.io]]></content>
      <categories>
        <category>others</category>
      </categories>
  </entry>
</search>
