<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[$k$ 近邻法]]></title>
    <url>%2F2018%2F12%2F01%2Fmarkdown_file-master%2Fstatistic_learning_method%2Fslm_chapter3%2F</url>
    <content type="text"><![CDATA[1 \(k\) 近邻法 \(k\) 近邻法的三个基本要素： \(k\)值的选择， 距离度量， 分类决策规则 ## 1.1 \(k\) 近邻算法 输入： 训练数据集 \[ T = \{ (x_1, y_1), (x_2, y_2),..., (x_N, y_N)\} \] 其中， \(x_i \in \mathcal{X} \subseteq R^n\)为实例的特征向量， \(y_i \in \mathcal{Y} ＝\{c_1， c_2,…,c_K\}\) 为实例的类别， \(i＝1,2,…,N\)； 实例特征向量\(x\)； 输出： 实例\(x\)所属的类\(y\). 根据给定的距离度量， 在训练集\(T\)中找出与\(x\)最邻近的\(k\)个点， 涵盖这\(k\)个点的\(x\)的邻域记作\(N_k(x)\)； 在\(N_k(x)\)中根据分类决策规则（如多数表决） 决定\(x\)的类别\(y\)： \[ y = \arg \max\limits_{c_j} \sum\limits_{x_i \in N_k (x)} I(y_i = c_j), i= 1,2,..,N; j=1,2,...,K \] 式中\(I\)为指示函数，即当\(y_i = c_j\)时\(I\)为1， 否则为0。 最近邻算法：取 \(k=1\) 时 1.2 距离度量 \(L_p\) 距离 \[ L_p (x_i, x_j) = \left( \sum\limits_{l=1}^n | x_i^{(l)} -x_j^{(l)} |^p \right)^{\frac{1}{p}} \] 这里的\(p\geq 1\),当\(p​\)取不同的值的时候会得到不同的距离。 当 \(p=2\)时， 称为欧式距离（Euclidean distance） 当 \(p=1\)时， 称为曼哈顿距离（Manhattan distance） 当 \(p=\infty\)时， 取各个坐标距离的最大值，即 \(L_{\infty} (x_i, x_j) = \max\limits_l |x_i^{(l)}-x_j^{(l)}|\) 1.3 \(k\) 值的选择 在应用中，$ k\(值一般取一个比较小的数值。 通常采用交叉验证法来选取最优的\)k$值. 1.4 分类决策规则 \(k\) 近邻法的决策规则实际上是多数表决，如果分类函数的损失函数是0-1损失函数，将损失函数表示为： \[f: R^n \rightarrow \{ c_1, c_2, ..., c_K \}\] 那么误分类的函数概率就是： \[P(Y \neq f(X)) = 1-P(Y=f(X))\] 对给定的实例 \(x \in X\), 其最近邻的\(k\) 个训练实例点构成集合\(N_k (x)\) 。如果涵盖\(N_k(x)\) 的类别是\(c_j\), 那么误分类率是: \[\frac{1}{k} \sum\limits_{x_i \in N_k(x)} I(y_i \neq c_j)= 1- \frac{1}{k} \sum\limits_{x_i \in N_k(x)}I(y_i =c_j)\] 多数表决规则等价于经验风险最小化。 1.5 \(k\)近邻法的实现： kd树 1.5.1 构造平衡kd树 输入: \(k\) 维空间数据集 \(T = \{ x_1, x_2, ..., x_N \}\), 其中\(x_i = (x_i^{(1)}, x_i^{(2)}, x_i^{(3)}, ..., x_i^{(k)})^T\), \(i = 1, 2, ..., N\) 输出： kd树 (1) 开始： - 构造根结点， 根结点对应于包含\(T\)的\(k\)维空间的超矩形区域。 选择\(x^{(1)}\)为坐标轴， 以\(T\)中所有实例的\(x^{(1)}\)坐标的中位数为切分点， 将根结点对应的超矩形区域切分为两个子区域。 切分由通过切分点并与坐标轴\(x^{(1)}\)垂直的超平面实现。 - 由根结点生成深度为1的左、右子结点： 左子结点对应坐标\(x^{(1)}\)小于切分点的子区域， 右子结点对应于坐标\(x^{(1)}\)大于切分点的子区域。 - 将落在切分超平面上的实例点保存在根结点。 重复： 对深度为\(j\)的结点， 选择\(x^{(l)}\)为切分的坐标轴， \(l＝j( \text{mod} k)+1\)， 以该结点的区域中所有实例的\(x^{(l)}\)坐标的中位数为切分点， 将该结点对应的超矩形区域切分为两个子区域。 切分由通过切分点并与坐标轴\(x^{(l)}\)垂直的超平面实现。 由该结点生成深度为\(j+1\)的左、 右子结点： 左子结点对应坐标\(x^{(l)}\)小于切分点的子区 域， 右子结点对应坐标\(x^{(l)}\)大于切分点的子区域。 直到两个子区域没有实例存在时停止。 从而形成kd树的区域划分。 1.5.2 搜索kd树 输入： 已构造的kd树； 目标点\(x\)； 输出： \(x\)的最近邻。 - 在kd树中找出包含目标点\(x\)的叶结点： 从根结点出发， 递归地向下访问kd树。 若目标点\(x\)当前维的坐标小于切分点的坐标， 则移动到左子结点， 否则移动到右子结点。 直到子结点为叶结点为止。 - 以此叶结点为“当前最近点”。 - 递归地向上回退， 在每个结点进行以下操作： - a. 如果该结点保存的实例点比当前最近点距离目标点更近， 则以该实例点为“当前最近点”。 - b. - 当前最近点一定存在于该结点一个子结点对应的区域。 检查该子结点的父结点的另一子结点对应的区域是否有更近的点。 具体地， 检查另一子结点对应的区域是否与以目标点为球心、 以目标点与“当前最近点”间的距离为半径的超球体相交。 - 如果相交， 可能在另一个子结点对应的区域内存在距目标点更近的点， 移动到另一个子结点。 接着， 递归地进行最近邻搜索 - 如果不相交， 向上回退。 - 当回退到根结点时， 搜索结束。 最后的“当前最近点”即为\(x\)的最近邻点。 如果实例点是随机分布的， kd树搜索的平均计算复杂度是\(O(\log N)\)， 这里\(N\)是训练实例数。 kd树更适用于训练实例数远大于空间维数时的\(k\)近邻搜索。 当空间维数接近训练实例数时， 它的效率会迅速下降， 几乎接近线性扫描]]></content>
      <categories>
        <category>ML</category>
        <category>统计学习方法</category>
      </categories>
      <tags>
        <tag>$k$近邻法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[朴素贝叶斯法]]></title>
    <url>%2F2018%2F11%2F30%2Fmarkdown_file-master%2Fstatistic_learning_method%2Fslm_chapter4%2F</url>
    <content type="text"><![CDATA[朴素贝叶斯法 1 极大似然估计， 最大后验， 贝叶斯估计。 极大似然估计 根据实验数据构造似然函数: \(f(\theta)\). 求取得最大值的参数\(\theta\). \(\arg\limits_{\theta} \max f(\theta)\) 最大后验估计 求最大后验 \(P(\theta |x_0) = \frac{P(x_0 | \theta)\times P(\theta)}{P(x_0)}\). 其中 \(P(\theta)\)是先验分布， \(P(x_0 | \theta)\)是似然函数。 因为\(P(x_0)\) 由实验结果决定，所以上述等价于最大化 \(P(x_0| \theta) \times P(\theta)\) 所以这个和极大似然估计相比，多了一项先验分布。 也是用来求 \(\arg\limits_{\theta} \max P(x_0| \theta) \times P(\theta)\) 贝叶斯估计 求后验分布 \(P(\theta | X) = \frac{P(X| \theta) \times P(\theta)}{P(X)}\), 通过实验可以确定 \(P(X)\), \(P(X|\theta)\) 是似然函数， \(P(\theta)\) 是先验分布。 在极大似然估计和 最大后验估计中都是通过做得的最为频繁发生的数据结果来推出当\(\theta\)满足某个值的时候能够最大可能性的得到这个结果。 贝叶斯估计是认为 \(\theta\)也是一个分布， 为了求解这个分布往往需要我们将先验分布和后验分布假设为共轭先验。 2 朴素贝叶斯法的学习和分类 2.1 朴素贝叶斯法基本概念 符号说明： \(x_i^{(j)}\) 是第\(i\)个样本的第\(j\)个特征； \(a_{jl}\) 是第\(j\)个特征可能取的第\(l\)个值； \(I\)是指示函数， 满足条件为1，否则为0. 我们首先看一张关于不同的名称之间关系的图(来源)： 根据这张图我们可以知道贝叶斯法和最大后验估计（maximum a posteriori estimation）是一样的。 只是采用了最大后验的方法来进行分类。 贝叶斯公式：我们首先列出在给定一个实例 \(X\) 的情况下对标签 \(Y\) 进行预测的公式（贝叶斯公式）： \[ P(Y= c_k| X=x) = \frac{P(X=x | Y=c_k)P(Y=c_k)}{\sum\limits_k P(X=x|Y=c_k)P(Y=c_k)}\] 预测未知数据就要求解的参数：我们需要通过已有的实验数据对未知的数据进行预测， 那么我们需要通过已有的数据得到先验概率分布 \(P(Y=c_k), k=1,2,...,K\) 和条件概率分布 \(P(X=x|Y=c_k) = P(X^{(1)}=x^{(1)}, ..., X^{(n)}=x^{(n)}|Y=c_k), k=1,2,...,K\) 。 最大似然求解先验概率分布：先验概率分布 \(P(Y=c_k), k=1,2...,K\)是容易通过已有数据得到的, 利用极大似然估计就能够得到： $P(Y=c_k) = , l=1,2,..,K $. 将 \(P(Y=c_k)\) 看做是参数， 似然函数是 \(P(Y=c_k) * N\). 参数过多：条件概率分布 \(P(X=x|Y=c_k) = P(X^{(1)}=x^{(1)}, ..., X^{(n)}=x^{(n)}|Y=c_k), k=1,2,...,K\) 是非常难求的。 因为对应于每个\(x^{j}\) 的可能取值有 \(S_j\) 个， 那么参数的个数有 \(K\prod\limits_{j=1}^nS_j\) 个。这里的参数指的就是 每一个条件概率 \(P(X=x|Y=c_k)\)。 比如\(n=10, S_j =10, K=10\) ,那么参数量是\(10^{11}\) ,显然就太多了。 条件独立性假设：为了解决条件概率参数太多的问题，贝叶斯法对条件概率做了条件独立的假设： \[ P(X=x|Y=c_k) = P(X^{(1)}=x^{(1)}, ..., X^{(n)}=x^{(n)}|Y=c_k)= \prod\limits_{j=1}^nP(X^{(j)}=x^{(j)}|Y=c_k)\] 引入了条件独立性假设的后验概率计算： \[\begin{align} P(Y= c_k| X=x) &amp;= \frac{P(X=x | Y=c_k)P(Y=c_k)}{\sum\limits_k P(X=x|Y=c_k)P(Y=c_k)} \\ &amp;= \frac{P(Y=c_k) \prod\limits_{j=1}^nP(X^{(j)}=x^{(j)}|Y=c_k) }{\sum\limits_k P(Y=c_k)\prod\limits_{j=1}^nP(X^{(j)}=x^{(j)}|Y=c_k) }\end{align} \] 贝叶斯分类器： \[y=f(x) = \arg\max\limits_{c_k} \frac{P(Y=c_k) \prod\limits_{j=1}^nP(X^{(j)}=x^{(j)}|Y=c_k) }{\sum\limits_k P(Y=c_k)\prod\limits_{j=1}^nP(X^{(j)}=x^{(j)}|Y=c_k) }\] 简化： 因为对于不同的 \(c_k\) 在已经学习好的模型（先验概率通过最大似然求出来了，条件概率通过条件独立性假设求出来了）上是一个常数，所以可以忽略掉分母： \[y=f(x) = \arg\max\limits_{c_k} P(Y=c_k) \prod\limits_{j=1}^nP(X^{(j)}=x^{(j)}|Y=c_k) \] 2.2 后验概率最大化的含义 朴素贝叶斯法将实例分到后验概率最大的类中， 这等价于期望风险最小化 证明： 损失函数为0-1损失函数。 \[ \begin{align} L(Y,f(X)) = \begin{cases} 1, Y\neq f(X) \\ 0, Y=f(X) \end{cases} \end{align} \] 期望风险函数等于 \(R_{exp}(f) = E[L(Y,f(X))]\) 在这里取联合期望为： \(R_{exp} (f) =E_{X} \sum\limits_{k=1}^K [L(c_k, f(X))]P(c_k | X)\) 为了使得期望风险最小， 只需要对\(X=x\) 逐个极小化，由此得到： \[ \begin{align} f(x) &amp;= \arg \min\limits_{y \in \mathcal{Y}} \sum\limits_{k=1}^K L(c_k , y) P(c_k|X=x) \\ &amp;= \arg \min_\limits{y \in \mathcal{Y}} \sum\limits_{k=1}^K P(y \neq c_k |X=x) \\ &amp;= \arg \min_\limits{y \in \mathcal{Y}} (1-P(y=c_k|X=c_k)) \\ &amp;= \arg \max_\limits{y \in \mathcal{Y}} P(y=c_k |X=x) \end{align} \] 所以，根据期望风险最小化准则就得到了后验概率最大化准则。 \[ f(x)= \arg \max_\limits{y \in \mathcal{Y}} P(y=c_k |X=x) \] 2.3 极大似然估计求解参数值 先验概率 \[ P(Y=c_k) = \frac{\sum\limits_{i=1}^N I(y_i = c_k)}{N}, k=1,2,...,K \] 条件概率 \[ \begin{align} P(X^{(j)}=a_{jl} | Y=c_k) = \frac{\sum\limits_{i=1}^{N}I(x_i^{(j)},y_i = c_k)}{\sum\limits_{i=1}^NI(y_i = c_k)} \\ j=1,2,...,n; l=1,2,...,S_j; k=1,2,...,K \end{align} \] 3 朴素贝叶斯算法（naive Bayes algorithm） 利用极大似然估计计算先验概率 \(P(Y=c_k)\) 和条件概率 \(P(X^{(j)}=a_{jl}|Y=c_k)\) 。 计算 \[ P(Y=c_k) \prod\limits_{j=1}^nP(X^{(j)}=x^{(j)}|Y=c_k) \] 确定类别 \[ y = \arg\max\limits_{c_k} P(Y=c_k) \prod\limits_{j=1}^nP(X^{(j)}=x^{(j)}|Y=c_k) \] 4 利用贝叶斯估计取代最大似然估计 用极大似然估计可能会出现所要估计的概率值为0的情况。 这时会影响到后验概率的计算结果， 使分类产生偏差。解决这一问题的方法是采用贝叶斯估计。 具体地， 条件概率的贝叶斯估计是： \[ P_\lambda(X^{(j)}=a_{jl} | Y=c_k) = \frac{\sum\limits_{i=1}^{N}I(x_i^{(j)},y_i = c_k) + \lambda}{\sum\limits_{i=1}^NI(y_i = c_k) + S_j\lambda} \] \(\lambda&gt;0\) , 当 \(\lambda=0\)的时候就是极大似然估计。 常取 \(\lambda=1\) 称为拉普拉斯平滑。 显然对于任意依噶条件概率都大于0 并且求和为1. 先验概率的贝叶斯估计是： \[ P_\lambda (Y=c_k) =\frac{\sum\limits_{i=1}^N I (y_i = c_k)+\lambda}{N+K\lambda} \] 5 贝叶斯估计， 最大后验， 最大似然， 朴素贝叶斯法 所有的这些方法都是建立在贝叶斯公式的基础上的。 最大后验，最大似然和贝叶斯估计都是对参数进行估计。 - 最大似然:它假设随机变量 \(X\) 满足某个分布，其中具有参数\(\theta\) , 根据 \(\theta\)我们可以写出得到某一组实验数据的概率表达式（似然函数）， 通过实验我们得到了一组实验数据\(x_0\), 我们通过对似然函数进行取对数然后求导的方法得到一个确定的\(\theta\)值，使得得到这组实验数据的概率最大。 最大后验：最大后验估计在最大似然的基础上引入了先验概率。 通过贝叶斯估计， 也能够得到不同的\(\theta\) 值得到\(X\) 的概率。 我们希望计算 \(\theta\)使得实验得到的\(x_0\) 在该后验概率中发生的可能性是最高的。 贝叶斯估计： 最大似然和最大后验，只是希望得到使得实验数据可能性最高的一个参数值，而贝叶斯估计中希望确定参数\(\theta\) 的分布， 为了能够确定这个分布， 我们需要使得贝叶斯公式得到的结果满足概率的几个要素（积分为1， 单调）。 因此常用共轭先验的方法来简化模型。 朴素贝叶斯法：朴素贝叶斯法是建立在贝叶斯定理和条件独立性假设下的分类算法。 在利用朴素贝叶斯法建立分类模型时，相关的先验分布， 条件分布的参数一般是通过最大似然的方法和贝叶斯估计的方法求得的。 贝叶斯法是一种生成模型]]></content>
      <categories>
        <category>ML</category>
        <category>统计学习方法</category>
      </categories>
      <tags>
        <tag>朴素贝叶斯</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[感知器学习算法]]></title>
    <url>%2F2018%2F11%2F29%2Fmarkdown_file-master%2Fstatistic_learning_method%2Fslm_chapter2%2F</url>
    <content type="text"><![CDATA[1 感知机 1.1 感知机模型 定义： \[ \begin{align} f(x) &amp;= \text{sign} (wx+b) \\ \text{sign}(x) &amp;= \begin{cases} +1, x \leq 0 \\ -1, x&lt;0 \end{cases} \end{align} \] 属性： 线性分类模型， 判别模型 假设空间： 所有线性分类模型 损失函数（经验风险损失）： \[L(w,b) = -\sum\limits_{x_i \in M} y_i (wx_i +b)\] 其中 \(M\) 是误分类点的集合。 因为对于 \((wx_i +b) &gt;0\) 的情况其预测标签为1， 对于误分类的情况实际标签为\(-1\)。 因此，需要使得 \((wx_i +b)​\) 往0处靠近。 所以可以采用这个作为损失函数。 1.2 感知器学习算法 方法： 随机梯度下降算法(stochastic gradient descent) 梯度： \[ \begin{align} \Delta_w L(w,b) &amp;= -\sum_{x_i \in M} y_i x_i \\ \Delta_b L(w,b) &amp;= -\sum_{x_i \in M} y_i \end{align} \] 梯度的更新 随机的选择一个误分点进行更新： \[ \begin{align} w &amp;= w+\eta y_i x_i \\ b &amp;= b+\eta y_i \end{align} \] \(0&lt;\eta\leq1\) 在统计学习中又称为学习率. 例子1 如图2.2所示的训练数据集， 其正实例点是\(x_1＝(3,3)^T， x_2＝(4,3)^T​\)， 负实例点是\(x_3＝(1,1)^T​\)， 试用感知机学习算法的原始形式求感知机模型\(f(x)＝\text{sign}(w·x+b)​\)。 这里， \(w＝(w^{(1)},w^{(2)})T， x＝(x^{(1)},x^{(2)})\) 代码： 1234567891011121314151617import numpy as npx = np.matrix([[3, 3], [4, 3], [1, 1]])y = [1, 1, -1]w = np.matrix([[0], [0]])b = 0lr = 1flag = 0while flag&lt;3: flag = 0 for i in range(len(data)): tmp = (data[i]*w + b) * y[i] if (tmp[0, 0] &lt;= 0): # 被误分 w = w + lr*y[i]*x[i].T b = b + lr*y[i] print(w.T, b) else: flag += 1 结果： 12345678[[3 3]][[3 3]] 1[[2 2]] 0[[1 1]] -1[[0 0]] -2[[3 3]] -1[[2 2]] -2[[1 1]] -3 1.3 算法的收敛性 1.4 感知器学习算法的对偶形式 1.4.1 说明： 感知器采用随机梯度下降的方法进行梯度下降的迭代过程如下： \[ \begin{align} w &amp;= w + \eta y_i x_i \\ b &amp;= b + \eta y_i \end{align} \] 在经过\(n\) 次的迭代之后，\(w\) 和 \(b\) 受到第\(i\)个样本\((x_i ,y_i)\)的影响所改变值分别是 $n_i y_i x_i $ 和 \(n_i \eta y_i\)。\(n_i\)表示第 \(i\)个样本出现错判的次数。 \(\eta\) 是学习率。 用\(\alpha_i\) 表示\(n_i \eta\) 因此，不难得到最后的\(w\) 和 \(b\) 分别是： \[ \begin{align} w &amp;= \sum\limits_{i=1}^N \alpha_i y_ix_i \\ b &amp;= \sum\limits_{i=1}^N \alpha_i y_i \end{align} \] \(n_i\) 又称为第\(i\)个实例点更新的次数，实例点更新次数越多说明该点越接近超平面，也就越难正确分类。 1.4.2 算法 输入: 训练数据集\(T = \{(x_1， y_1),(x_2,y_2),...,(x_N,y_N)\}\)， 其中$x_i=R_n, y_i={-1,+1}, \[ i=1,2,...,N$; 学习率 $\eta$ $(0&lt;\eta \leq1)$。 **输出**: $\alpha,b$；感知机模型$f(x)＝\text{sign}\left( \sum\limits_{j=1}^N \alpha_j y_j x_j \cdot x+b \right)$。 其中 $\alpha = (\alpha_1, \alpha_2, ..., \alpha_N)^T$ (1) $\alpha = 0, b = 0$ (2) 在训练集中选取数据$(x_i, y_i)$ (3) 如果 $y_i \left( \sum\limits_{j=1}^N \alpha_j y_j x_j \cdot x+b \right) \leq 0$: \] \[\begin{align} \alpha_i &amp;= \alpha_i +\eta\\ b &amp;= b + \eta y_i \end{align}\] \[ (4) 转至（2）直到没有误分类数据。 对偶形式中训练实例仅以内积的形式出现。 为了方便， 可以预先将训练集中实例间的内积计算出来并以矩阵的形式存储， 这个矩阵就是所谓的Gram矩阵（Gram matrix） \] G = [x_i x_j]_{N N} $$ 1.4.3 例子 数据同例1， 正样本点是\(x_1＝(3,3)^T， x_2＝(4,3)^T\)， 负样本点是\(x_3＝(1,1)^T\)， 试用感知机学习算法对偶形式求感知机模型. - 代码 123456789101112131415161718192021222324252627282930import numpy as np# 变量初始化x = np.matrix([[3, 3], [4, 3], [1, 1]])y = np.matrix([[1], [1], [-1]])alpha = np.matrix([0, 0, 0])b = 0lr = 1# 计算Gamma 矩阵G = np.matmul(x, x.T)# 迭代更新 alpha 和 bnum = 0while num&lt;3: num = 0 for i in range(len(x)): tmp = np.sum(np.multiply(np.multiply(alpha, y.T), G[i] )) tmp += b tmp *= y[i, 0] if tmp &lt;= 0: alpha[0, i] += lr b += y[i]*lr print(alpha, b) else: num += 1 w = np.multiply(np.multiply(alpha.T, y), x)w = np.sum(w, 0)print("w:", w, " b:", b) 结果 12345678[[1 0 0]] [[1]][[1 0 1]] [[0]][[1 0 2]] [[-1]][[1 0 3]] [[-2]][[2 0 3]] [[-1]][[2 0 4]] [[-2]][[2 0 5]] [[-3]]w: [[1 1]] b: [[-3]]]]></content>
      <categories>
        <category>ML</category>
        <category>统计学习方法</category>
      </categories>
      <tags>
        <tag>感知器</tag>
        <tag>线性分类， 对偶问题</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[统计学习方法概论]]></title>
    <url>%2F2018%2F11%2F27%2Fmarkdown_file-master%2Fstatistic_learning_method%2Fslm_chapter1%2F</url>
    <content type="text"><![CDATA[1 统计学习 1.1 统计学习的特点 平台是计算机和网络 研究对象是数据 目的是对数据进行预测和分析 以方法为中心 （构建模型） 是概率论，统计学，信息论， 计算理论等多个领域的交叉学科 1.2 统计学习方法的三个要素 模型的假设空间（模型） 模型选择的准则（策略） 模型学习的算法（算法） 1.3 分类 监督学习 非监督学习 半监督学习 强化学习 2 监督学习 2.1 基本概念 符号集合 符号 含义 \(X\) 输入变量， 文中的所有变量都是列向量 \(Y\) 输出变量， 文中的所有变量都是列向量 \(x\) 输入变量的取值 \(x=(x^{(1)}, x^{(2)},...,x^{(i)},...,x^{(n)})^T\) \(x_i\) 第\(i\)个变量的取值 \(x_i = (x_i^{(1)}, x_i^{(2)},...,x_i^{(i)},...,x_i^{(n)})^T\) \(T\) 训练数据的集合 \(T=\{(x_1,y_1), (x_2,y_2), ..., (x_N, y_N)\}\) \(\mathcal{X}\) 由输入变量 \(X\) 组成的输入空间 \(\mathcal{Y}\) 由输出变量 \(Y\) 组成的输入空间 \(\mathcal{F}\) 假设空间（模型空间，自己取得名字） \(L(Y, f(X))\) 由模型的预测\(f(x)\) 和 实际标签\(Y\) 组成的损失函数 输入空间和输出空间 将输入和输出所有可能取值的集合称为输入空间。 ### 特征向量（feature vector） 每个具体的输入是一个实例（instance），通常由特征向量表示。 ### 特征空间（feature space） 所有的特征向量存在的空间称为特征空间。 ### 回归问题和分类问题 - 回归问题： 输入变量和输出变量均为连续变量的预测问题。 - 分类问题： 输出变量为有限个离散变量的预测问题为分类问题。 ### 联合概率分布和假设空间 - 监督学习的基本假设： 假设数据之间存在一定的统计规律， \(X\) 和 \(Y\)之间存在着联合概率分布。 并且认为训练数据和测试数据是依联合概率分布 \(P(X,Y)\) 独立同分布产生的。 - 假设空间（hypothsis space）： 输入输出之间映射的集合（所有可能的模型）。 由条件概率 \(P(Y|X)\) 或者决策函数（decision function) \(Y=f(x)\) 表示。 3 统计学习中的三要素 统计学习方法由三部分组成可以简单的表示： 方法 = 模型+策略+算法 3.1 模型 在监督学习过程中模型就是所学的条件概率分布或者决策函数。 模型的假设空间\(\mathcal{F}\)由所有可能的条件概率分布或者决策函数组成。 因此假设空间\(\mathcal{F}\)可以通过下面这些式子表示。 决策函数的集合 普通的写法 \[ \mathcal{F} = \{ f| Y = f(X) \} \] 由于假设空间通常是由一个参数向量决定的函数族，所以也可以写成 \[ \mathcal{F} = \{ f| Y = f_\theta (X) \} \] 条件概率的集合 一般的写法 \[ \mathcal{F} = \{ P| P(Y|X) \} \] 加上参数的写法 \[ \mathcal{F} = \{ P| P_\theta (Y|X) \} \] 3.2 策略 tags: 损失函数， 风险函数， 期望风险， 期望损失， 经验风险， 经验损失， 结构风险 ### 3.2.1 极大似然估计 + 最大后验概率估计 - 极大似然估计（maximum likelihood estimation 简称MLE） 通过实验得到实验结果 \(x_0\)， 通过先验知识确定这个实验结果出现的概率函数称为似然函数 \(P(x_0|\theta)\), 最后通过取对数值然后求导等方法求得使似然函数取最大值事的参数 \(\theta\)。 - 最大后验概率估计(maximum a posterior probability estimation 简称MAP) 通过实验数据找到最合适的参数 \(P(\theta|x_0)\), 由于 \(P(\theta|x_0) = \frac{P(x_0|\theta) \times P(\theta)}{P(x_0)}\)， 因为 \(P(x_0)\) 可以通过实验得到，因此最大化后验只需要求最大化 \(P(x_0|\theta) \times P(\theta)\) 前半部分是似然函数， 后半部分是先验。 3.2.2 相关概念 损失函数（loss function）： 又称代价函数(cost function) 用来度量预测错误的程度。 损失函数是 \(f(X)\) 与 \(Y\) 的非负实值函数。 记为 \(L(Y, f(X))\)。 常见的损失函数 0-1 损失函数 (0-1 loss function) \[ L(Y,f(X)) = \begin{array}{lc} 1&amp;, Y\neq f(X) \\ 2&amp;,Y=f(X) \end{array} \] 平方损失函数（quadratic loss function） \[ L(Y,f(X)) = (Y-f(X))^2 \] 绝对值损失函数（absolute loss function） \[L(Y,f(X)) = |Y-f(X)| \] 对数损失函数（logarithmic loss function） 或者 对数似然损失函数 (likelihood loss function) \[ L(Y,P(Y|X)) = -\log (P(Y|X)) \] 风险函数（risk function） 又称 期望损失（expected loss） \[ R_{exp} (f) = E_p [L(Y, f(X))] = \int_{\mathcal{X} \times \mathcal{Y}} L(x, f(x)) P(x, y) dxdy\] 经验风险 （empirical risk） 又称 经验损失 （empirical loss） \[ R_{emp} (f) = \frac{1}{N} \sum\limits_i^N L(y_i, f(x_i)) \] 经验风险最小化与结构风险最小化 经验风险最小化 \[\min\limits_{f \in \mathcal{F}} \frac{1}{N} \sum\limits_{i=1}^N L(y_i, f(x_i))\] 当模型是条件概率分布，损失函数是对数损失函数，经验风险最小化就等价于最大似然估计。 结构风险最小化 结构风险最小化(structural risk minimization, SRM)： $R_{srm} (f) = _{i=1}^N L(y_i, f(x_i)) +J(f) $ \(J(f)\) 是定义在假设空间 \(\mathcal{F}\) 上的泛函，模型越复杂越大。\(\min R_{srm}(f)\) 当模型是条件概率分布，损失函数是对数损失函数, 模型的复杂度由模型的先验概率表示时，结构风险最小化就等价于最大后验概率估计。 3.3 算法 算法： 学习模型的具体计算方法。 统计机器学习基于训练数据集，根据学习策略（模型） ，从假设空间中通过相应的算法求解最优模型。 统计学习问题可以归结为最优化问题。 4. 模型的评估和模型的选择 注：1.统计学习方法具体采用的损失函数未必是评估时使用的损失函数。 2. 通常将学习方法对未知数据的预测能力称为泛化能力（generalization ability） - 过拟合： 参数过多， 已知数据预测很好， 未知数据预测很差 - 奥卡姆剃刀（Occam's razor） 原理：能解释已知数据，并且十分简单才是最好的模型。 ## 4.1 模型选择的方法 - 正则化：${f} {i=1}^N L(y_i, f(x_i)) +J(f) $ 也就是结构风险最小化。 常用的正则化项包括对参数向量的一范式和二范式。 - 交叉验证：数据不充分的时候切分数据集反复进行训练，测试和模型选择。 - 简单交叉验证 - S折交叉验证 - 留一交叉验证 4.2 泛化误差, 泛化误差上界（29页） 证明(......) 训练误差小的模型， 其泛化误差也会小 5 生成模型和判别模型 5.1 生成模型 由数据学习联合概率分布 \(P(X, Y)\), 求出条件概率分布 \(P(Y|X)\) 作为预测的模型，即生成模型。 $P(Y|X) = $ 常用的方法： 朴素贝叶斯方法和隐马尔科夫模型 特点： 1. 能够还原出联合概率分布\(P(X, Y)\)； 2.学习收敛速度快； 3. 当存在隐变量的时候任然能够用生成模型学习。 5.2 判别模型 由数据直接学习决策函数 \(f(x)\) 或者条件概率分布 \(P(Y|X)\) 作为预测的模型。 判别模型关系的是给定的 \(X\) 应该预测什么样的输出 \(Y\)。 常用的方法：k 近邻法， 感知器， 决策树， 逻辑斯迪克回归， 最大熵模型， 支持向量机， 提升方法和条件随机场等。 特点： 1. 直接学习条件概率\(P(Y|X)\)或者决策函数\(f(X)\) ,直接面对预测，往往学习率更高； 2. 可以对数据进行各种程度上的抽象，定义特征并使用特征，因此可以简化学习问题。 6 分类问题 评价指标 精确率： \(P = \frac{TP}{TP+FP}\) 召回率： \(R = \frac{TP}{TP+FN}\) \(F_1\)值：\(\frac{2}{F_1} = \frac{1}{P} + \frac{1}{R}\) =&gt; \(F_1 = \frac{2TP}{2TP+FP+FN}\) 主要的分类方法： k近邻法、 感知机、 朴素贝叶斯法、 决策树、决策列表、 逻辑斯谛回归模型、 支持向量机、 提升方法、 贝叶斯网络、 神经网络、Winnow 等。 7 标注问题 训练数据： \(T = \{ (x_1, y_1), (x_2, y_2), ..., (x_N, y_N) \}\)。 其中 \(x_i = (x_i^{(1)}, x_i^{(2)},..., x_i^{(n)})^T\) 对应的标记序列是：\(y_i = (y_i^{(1)}, y_i^{(2)}, ..., y_i^{(n)})^T\)。 学习系统： 表示为条件概率为： \(P(Y^{(1)}, Y^{(2)}, ..., Y^{(n)}| X^{(1)}, X^{(2)}, ..., X^{(n)})\) 评价指标： 和分类问题一样，标注准确率， 精确率和召回率。 学习方法： 隐马尔可夫模型， 条件随机场 8 回归问题 回归模型表示从输入变量到输出变量之间映射的函数， 回归问题的学习等价于函数拟合。 - 模型： \(Y = f(X)\) - 损失函数： 平方损失函数（在此情况下可以采用最小二乘法求解）。 9 习题 9.1 说明伯努利模型的极大似然估计以及贝叶斯估计中的统计学习方法三要素。 伯努利模型是定义在取值为0与1的随机变量上的概率分布。 假设观测到伯努利模型n次独立的数据生成结果， 其中k次的结果为1， 这时可以用极大似然估计或贝叶斯估计来估计结果为1的概率。 统计学习方法三要素： 模型， 策略， 算法 极大似然估计： 介绍： 已经通过实验获取得到了实验结果 \(x_0\), 找到一组参数使得理论上生成实验结果 \(P(x_0 | \theta )\) 的概率是最大的. 结合伯努利模型： 在 \(n\) 次独立同分布的实验中，我们通过实验得到了一组实验数据 \(x_0\), 比如这个实验是在抛硬币,\(n=10\), 参数 \(\theta\) 表示在每次独立的实验中硬币正面朝上的概率为\(\theta\)。 我们可以通过这组实验知道： 实验中出现 \(k\) 次正面朝上的概率是 \(\theta^k (1-\theta)^{n-k}\) 我们希望找到的参数 \(\theta\) 能够使得这个概率最大。 因此我们可以对这个概率公式取对数然后求导得到当\(\theta = \frac{k}{n}\) 的时候取得最大值。 三要素： 模型：伯努利模型； 策略： 对数损失函数； 算法： 求经验风险最小值， 求导。 贝叶斯估计 还没总结完， 太多了！]]></content>
      <categories>
        <category>ML</category>
        <category>统计学习方法</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[贝叶斯公式+最大似然估计+最大后验概率公式+贝叶斯估计]]></title>
    <url>%2F2018%2F11%2F26%2Fmarkdown_file-master%2Fstatistic_learning_method%2FBT_MLE_MAP%2F</url>
    <content type="text"><![CDATA[来源： https://blog.csdn.net/u011508640/article/details/7281598 # 贝叶斯公式+最大似然估计(MLE)+最大后验概率公式(MAP)+贝叶斯估计 ## 1.贝叶斯公式 \[ P(A|B) = \frac{ P(B|A) \times P(A) }{ P(B|A) \times P(A) + P(B|\sim A) \times P(\sim A) } \] - 作用： - 你有多大把握相信一件证据。 给定 \(B\) 的时候，你有多大的可能性会去相信 \(A\) 能够成立。 - 在做判断的时候需要考虑所有的因素。 - 一件很难发生的事情 \(P(A)\) 即使出现某个证据 \(B\) 和它强相关 \(P(B|A)\) 也要谨慎，因为证据可能来自其他虽然不是强相关但发生概率较高的事情 因为 \(P(B|\sim A) \times P(\sim A)\) 可能会比较大从而导致\(P(B|A)\) 比较小。 - 根据已知的或者主观容易断定的条件概率事件，计算出未知的或者较难评估的条件概率事件 2. 似然函数 对于函数 \(P(x| \theta)\): - 当 \(\theta\) 是已知的情况下， \(x\) 是变量， 这个函数叫做概率函数（probability function）, 用来描述对于不同的样本点 \(x\) , 其出现的概率是多少。 - 当 \(x\) 是已知的情况下， \(\theta\) 是变量， 这个函数叫做似然函数（likelihood function）, 用来描述对于不同的模型参数， 这个样本点出现的概率是多少。 3. 最大似然估计（maximum likelihood estimation : MLE） 最大似然估计的核心思想是认为当前发生的事件是概率最大的 构造一个关于参数 \(\theta\) 的函数， 这个函数用来表示在已知的一组实验中产生了一组实验数据 \(x_0\) 的可能性。 在抛硬币实验中，每次抛硬币出现正反的概率满足二项分布。 比如抛了10次，出现的一组实验数据 \(x_0=[0111101110]\)。 似然函数为： \(f(\theta) = ((1−\theta) × \theta × \theta × \theta × \theta × (1 − \theta)× \theta × \theta × \theta ×(1−\theta))=\theta^7 \times (1 - \theta)^3\) 计算使似然函数最大的参数值， 一般先取对数然后计算。 \(\log f(\theta) = 7\log \theta + 3\log (1-\theta)\) 求导可以得到： \(\frac{7-10\theta}{\theta (1-\theta)}\) 可以得到当\(\theta = 0.7\) 的时候能够得到最大值。 ## 4. 最大后验概率估计（maximum a posterior probability estimation: MAP） 最大似然估计的目的是通过求解得到 \(\theta\) 使得似然函数 \(P(x_0|\theta)\) 达到最大。 而最大后验概率估计是在最大似然估计的情况下考虑先验概率分布\(P(\theta)\) 。使得 \(P(\theta) \times P(x_0 | \theta)\) 达到最大。 最大后验概率估计的目的其实是为了最大化后验： $P(| x_0) = $ 因为 \(P(x_0)\) 是可以通过做实验得到的。 所以只需要求解 \(P(\theta) \times P(x_0 | \theta)\) 使其最大。 最大后验的名字来源于 \(P(\theta | x_0)\) 就是要在已有实验数据的情况下求解最合理的参数。 5. 贝叶斯估计 （感觉这部分理解的不是特别到位） 介绍： 不论是极大似然估计还是最大后验分布，我们都是通过构造一个似然函数（最大后验分布中还需要假设先验分布）， 来构建一个模型， 最后利用这个对数似然函数作为损失函数来求解相应的参数， 当参数固定的时候。模型也就确定了。 贝叶斯估计和最大后验相比目的不是为了得到一个最可靠的参数值，而是假设这个参数也服从某些分布。 因此我们需要通过一定的方法求解这个分布。 贝叶斯公式中\(P(\theta | X) = \frac{P(X | \theta) \times P(\theta)}{P(X)}\) 在最大后验估计和最大似然中有一个基本的假设是认为当前发生的事件概率最大， 通过带入具体的 \(X=x_0\) 来求解参数。因此可以不用考虑 分母， 因为当\(X=x0\) 的时候分母就是一个常数了。 但是现在我们希望求的是 \(P(\theta | X)\) 这个分布， 因此 \(P(X)\) 是不能够当成常数处理的， 这是一个分布。 \(P(X)\) 可以通过联合概率进行求解：\(\int_{\theta} P(X | \theta) d\theta\) . : 对于\(P(X)\) 要怎么求 我还不确定， 搞懂了再补吧! 注： \(P(X)\) 应该是通过实验作出来的， 当训练数据集确定了， 那么这个分布是能够确定下来的。 简便求解的方法： 将先验分布和后验分布构造成共轭先验。 那么可以将\(P(X)\) 看成一个常数。因为这样知道了后验分布通过积分为1容易求得均值方差。 6. 一个简单的例子 投硬币10次得到的结果是\(x_0 = [0111101110]\) - 最大似然函数， 上面已经说过了对应的似然函数是： \(f(\theta) =\theta^7 \times (1 - \theta)^3\) - 代码： 12345678910111213import mathimport matplotlib.pyplot as pltdef mle_value(): """最大似然估计： x表示 θ 值""" x = [0.001*i for i in range(0, 1000)] # 不同的参数 θ 的值 y = [i**7 * (1-i)**3 for i in x] # θ对应的似然函数值 print('对应最大值的θ是:', x[y.index(max(y))]) plt.plot(x, y) plt.xlabel('θ') plt.ylabel('likelihood function value') plt.show() 结果 根据先验知识假定 P(θ) 为均值为0.5， 方差为0.1 的高斯函数，可以画出对应的概率密度图&quot; 代码 12345678910111213def prior_value(): """根据先验知识假定 P(θ) 为均值为0.5， 方差为0.1 的高斯函数，所以可以画出 θ 和 P(θ) 的图像： 一个高斯分布的密度函数，密度越大可能性越大""" def p_theta(u): return 1/((2*math.pi*0.01)**(1/2))*math.exp(-(u-0.5)**2/(2*0.01)) x = [i*0.001 for i in range(0, 1000)] y = [p_theta(i) for i in x] print('对应最大概率密度的θ值是:', x[y.index(max(y))]) plt.plot(x, y) plt.xlabel('θ') plt.ylabel("p(θ)") plt.show() 结果 \(P(\theta)\) 的先验知识和似然函数\(P(x_0 | \theta)\) 可以画出后验的图 代码 123456789101112"""假定 p(θ) 满足均值为 0.5 方差为 0.1 的概率密度的情况下， 计算联合概率密度的值 p(xo|θ)*p(θ)， 联合概率反映了后验概率的数值大小 """ def p_theta(u): return (1/((2*math.pi*0.01)**(1/2))*math.exp(-(u-0.5)**2/(2*0.01))) * (u**7 *(1-u)**3) x = [i*0.001 for i in range(0, 1000)] y = [p_theta(i) for i in x] print('对应最大联合概率密度的θ值是:', x[y.index(max(y))]) plt.plot(x, y) plt.xlabel('θ') plt.ylabel("p(xo|θ)*p(θ)") plt.show() 结果 \(P(\theta)\) 的先验知识和似然函数\(P(x_0 | \theta)\) 通过多做几次实验可以得到更加准确的结果 代码 1234567891011121314def map_value100(): """ 实验了100次会得到的结果 """ def p_theta(u): return (1/((2*math.pi*0.01)**(1/2))* math.exp(-(u-0.5)**2/(2*0.01))) * (u**7 *(1-u)**3)**70*(u**7 *(1-u)**3)**30 x = [i*0.001 for i in range(0, 1000)] y = [p_theta(i) for i in x] print('对应最大联合概率密度的θ值是:', x[y.index(max(y))]) plt.plot(x, y) plt.xlabel('θ') plt.ylabel("p(xo|θ)*p(θ)") plt.show() 结果]]></content>
      <categories>
        <category>ML</category>
      </categories>
      <tags>
        <tag>贝叶斯公式， Bayes’ Theorem</tag>
        <tag>最大似然估计， 最大后验概率估计， MLE</tag>
        <tag>MAP</tag>
        <tag>maximum likelihood estimation</tag>
        <tag>maximum a posterior probability estimation</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[这是一篇对 hexo 中对 markdown 中各种格式支持的实验]]></title>
    <url>%2F2018%2F11%2F25%2Fmarkdown_file-master%2Fothers%2Fmarkdown_test%2F</url>
    <content type="text"><![CDATA[这是一篇对 hexo 中对各种格式支持的实验 添加图片 公式 插入公式 \(\frac{1}{2}=0.5\) , \[ \begin{align} y &amp;= \sigma (W[x,y]+b)\\ x &amp;= 0 \end{align} \] 插入表格 表头1 表头2 表头3 表头4 默认左对齐 左对齐 居中对其 右对齐 默认左对齐 左对齐 居中对其 右对齐 默认左对齐 左对齐 居中对其 右对齐 高亮：==哈哈哈哈== 删除线：哈哈哈 代码： 123456789101112import tensorflow as tfif __name__ == "__main__": sum = 0 for i in range(101, 200): flag = True for j in range(2，i//2+1: if i%j == 0: flag = False break if flag: sum += 1 print(sum) [^]: 这是一段脚注 这是一段引用 a b \(\mathcal{X}, \mathcal{Y}\) \[ L(Y,f(X)) = \left\{ \begin{align} 1&amp;, Y\neq f(X) \\ 2&amp;,Y=f(X) \end{align} \right\}​\]]]></content>
      <categories>
        <category>others</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[在机器学习中数据不平衡问题的解决]]></title>
    <url>%2F2018%2F11%2F25%2Fmarkdown_file-master%2Fothers%2F%E5%9C%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E6%95%B0%E6%8D%AE%E4%B8%8D%E5%B9%B3%E8%A1%A1%E9%97%AE%E9%A2%98%E7%9A%84%E8%A7%A3%E5%86%B3%2F</url>
    <content type="text"><![CDATA[在机器学习中数据不平衡问题的解决 出处： https://www.cnblogs.com/zhaokui/p/5101301.html ### 例子： 在所有的微博对应的评论数量划分为1到5这5个等级。 1少5多。 大部分的评论都很少，极少数的微博评论会非常的多。 如果我们要对一些微博的评论数量进行预测。 只要全部预测为1，就能够得到非常高的准确率， 显然这样的预测是没有意义的。 将问题分为4个类别 数据量 分布是否均匀 大 均匀 大 不均匀 小 均匀 小 不均匀 注： 当每个类别的数据量大于5000 个以上的时候，正负样本数量相差一个量级是能够接受的（经验之谈）。 主要的解决方法 采样 方法 做法 问题 解决方法 上采样 小样本复制多分 过拟合 加入随机扰动 下采样 剔除一部分大样本 信息损失 EasyEnsemble)：多次放回的独立采样构建多个独立的模型，然后将多个模型进行组合 BalanceCascade: 在EasyEnsemble的基础上前面训练得到的模型预测准确的样本不放回。NearMiss: 利用KNN挑选出最具代表性的大众样本 数据合成 SMOT 方法： 对于小众样本 \(x_i \in S_{min}\) 从它的 k 近邻中随机选取一个点\(\hat{x}\)。 生成新的小众样本 \(x_{new}=x_i + (\hat{x}-x_i) \times \delta\) , 其中 \(\delta \in [0,1]\) 是一个随机数。 存在的问题： 1. 增加了类之间重叠的可能性。 2. 生成了一些没有提供有益信息的样本。 下面两种方法用来解决这些问题。 Borderline-SMOTE 只对小众样本中那些 k 近邻中大部分是大众样本的点通过SMOTE生成新样本。 因为这些样本往往是边界样本 ADASYN 首先计算每个小众样本在需要使整个数据集达到平衡时需要增加的数据量记为 \(G\). 再计算对于具体的一个小众样本中每个点需要生成的样本占 \(G\) 的比例。 \[\mathcal{T}_i = \frac{\Delta_{ik}}{\sum_i \Delta_{ik}} \] 其中的\(\Delta_{ik}\) 是第\(i\) 个样本点中\(k\)近邻中大众样本的个数。 计算小众样本中每个点需要利用SMOT方法生成的点的个数： \(g_i = \mathcal{T}_i \times G\) 加权 对于不同的类别分成其他的类别时对应的损失是不同的。 将 \(c(i,j)\) 视为是把真实样本类别为 \(j\) 的时候分类成 \(i\) 时的损失。 该方法的难点在于如何确定 \(c(i,j)\). 一分类 当正负样本分布及其不均匀的时候，可以将这个模型看成是一分类或者异常检测的问题。 其中经典的工作包括 One-class SVM 。 方法的选择 正负样本均很少： 数据合成 正负样本比例悬殊：-分类 数据量还行，比例不是特别悬殊： 采样和加权的方法 采样和加权在数学上等价，但是实际中在计算资源合适的情况下，采样会好一点。 有空可以看看 Learning from Imbalanced Data 这篇综述。]]></content>
      <categories>
        <category>others</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>数据不平衡</tag>
        <tag>SMOT</tag>
        <tag>Border-line SMOT</tag>
        <tag>ADASYN</tag>
        <tag>采样， 加权， 一分类</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[利用hexo 和 github 搭建自己的博客 （Windows）]]></title>
    <url>%2F2018%2F11%2F23%2Fmarkdown_file-master%2Fothers%2F2018_11_23_hexo_blog%2F</url>
    <content type="text"><![CDATA[利用hexo 和 github 搭建自己的博客 （Windows） 安装Node.js 和 Node.js 环境 下载 Node.js 安装，可以直接选择添加环境变量 cmd 输入 node -v 会显示版本信息 安装 github win_git 下载很慢 打开cmd 输入 git --version 会显示 github 的版本信息 在github 中创建一个新的repository(仓库) 仓库名称的后缀名称必须是XX.github.io， 这里的名称应该是自己github 的名字（其他的不清楚会怎么样） Initialize this repository with a README 这个选项需要勾选 创建好之后， 找到sittings 按钮， 向下拉， 看到有个网站。如果没有的话需要将source 改为master branch. 主题也可以选一个，这个主题是readme对应的markdown 文件显示的主题。 然后点开， 你可以看到readme 中的一些内容了。 安装Hexo 创建一个文件夹 cd 到该目录下，将Hexo 安装在该目录下。 npm install hexo -g 安装 Hexo. （npm命令是安装node.js 的时候装上的。） hexo -v 可以确定安装成功与否 初始化该文件夹： hexo install （需要一点时间） 安装所需组件：npm install hexo g (我猜是编译吧) hexo s (启动服务器); 更具提示输入网址，可以进入初始页面。 如果进不去可能是端口被占用了通过如下方法修改端口号。 Ctrl +C 停止服务 hexo server -p 5000 (最后面那个是端口号) 将Hexo 和 github page 联系起来。 （下面这些步骤用git bash here 打开， git 安装好以后鼠标右键就有了） 如果是第一次的话，需要设置 git 的 user name 和 email (将本地的git 指定自己的账户) git config --global user.name &quot;XXXX&quot; , XXXX 是自己github 的用户名 git config --global user.email &quot;XXXX&quot;, XXXX是自己github的邮箱 利用ssh 和邮件生成秘钥和密匙。 cd ~/.ssh ssh-keygen -t rsa -C “XXXX@qq.com” 在C:.ssh 下面会得到两个文件， id_rsa和id_rsa.pub 添加密钥到ssh-agent: eval &quot;$(ssh-agent -s)&quot; 添加生成的SSH key到ssh-agent: ssh-add ~/.ssh/id_rsa 登录Github，点击头像下的settings，添加ssh 新建一个new ssh key，将id_rsa.pub文件里的内容复制到key中, Title 的内容可以随便填。 验证是否成功： ssh -T git@github.com 看到Hi 后面的内容表明成功了。 123Administrator@4H516J30FXZVCK3 MINGW64 /e/blog$ ssh -T git@github.comHi hekang123456! You've successfully authenticated, but GitHub does not provide shell access. 配置Hexo 和 git 之间建立连接 打开 _config.yml 修改最后的内容是 1234deploy: type: git repository: git@github.com:hekang123456/hekang123456.github.io.git branch: master repository 中的内容可以直接在 github 中对应的仓库中点下载， 选user SSH 复制下载中的连接地址 新建一篇博客 新建一篇博客，实际上是新建了一个markdown 在 “source/_posts/” 文件下面： hexo new post “hello word2！” 部署前安装一些扩展： npm install hexo-deployer-git --save 生成博客并且部署： hexo d -g 查看显示的博客内容： https:// XXXX.github.io]]></content>
      <categories>
        <category>others</category>
      </categories>
  </entry>
</search>
